{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radd import CORE, models, fit, vis, build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kyle/Dropbox/pro_idx_fits\n"
     ]
    }
   ],
   "source": [
    "%mkdir pro_idx_fits\n",
    "%cd pro_idx_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Model is prepared to fit xpro model (w/ exp dynamic bias) to subjects data,\n",
      "      allowing Drift-Rate to vary across levels of pGo (0, 20, 40, 60, 80, 100)\n",
      "\n",
      "      Optimize On, Garth \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = prodf_store.prodata\n",
    "\n",
    "m=build.Model(data=data, kind='xpro', fit_on='subjects', dynamic='exp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "      <th>60</th>\n",
       "      <th>80</th>\n",
       "      <th>100</th>\n",
       "      <th>hi10</th>\n",
       "      <th>hi30</th>\n",
       "      <th>hi50</th>\n",
       "      <th>hi70</th>\n",
       "      <th>hi90</th>\n",
       "      <th>lo10</th>\n",
       "      <th>lo30</th>\n",
       "      <th>lo50</th>\n",
       "      <th>lo70</th>\n",
       "      <th>lo90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.7209</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.4817</td>\n",
       "      <td>0.5033</td>\n",
       "      <td>0.5158</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.5499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.8487</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>0.4016</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.4782</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>0.5421</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>0.5485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9930</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.9952</td>\n",
       "      <td>2.2609</td>\n",
       "      <td>2.3048</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>0.5716</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.5452</td>\n",
       "      <td>0.5469</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.5497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0003</td>\n",
       "      <td>0.8832</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>-0.0823</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.5134</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.5438</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.5527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0411</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5224</td>\n",
       "      <td>0.5057</td>\n",
       "      <td>0.4895</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.5314</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.4289</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.3233</td>\n",
       "      <td>0.4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.8229</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>-0.0053</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>0.5126</td>\n",
       "      <td>0.5113</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>0.5306</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.5493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.4998</td>\n",
       "      <td>0.5168</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.5147</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.5427</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.5539</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0734</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.9838</td>\n",
       "      <td>2.2674</td>\n",
       "      <td>2.2797</td>\n",
       "      <td>0.5065</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.5726</td>\n",
       "      <td>0.5659</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.5485</td>\n",
       "      <td>0.5511</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1729</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.5016</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>1.1104</td>\n",
       "      <td>1.0348</td>\n",
       "      <td>0.5196</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.5557</td>\n",
       "      <td>0.5605</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.5576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.0342</td>\n",
       "      <td>0.9921</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>2.1909</td>\n",
       "      <td>2.3048</td>\n",
       "      <td>0.5344</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>0.5704</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>0.5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0058</td>\n",
       "      <td>0.9787</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>2.2853</td>\n",
       "      <td>2.2737</td>\n",
       "      <td>0.5259</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.5710</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>0.5460</td>\n",
       "      <td>0.5491</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.5583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.9936</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>2.2772</td>\n",
       "      <td>2.2709</td>\n",
       "      <td>0.5055</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.5509</td>\n",
       "      <td>0.5854</td>\n",
       "      <td>0.5648</td>\n",
       "      <td>0.5449</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>0.5112</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.5137</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.5574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.0419</td>\n",
       "      <td>0.9860</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>2.2208</td>\n",
       "      <td>2.2658</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.5717</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.5448</td>\n",
       "      <td>0.5463</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.5585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.0621</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>0.9154</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>2.2155</td>\n",
       "      <td>2.2617</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.5567</td>\n",
       "      <td>0.5727</td>\n",
       "      <td>0.5604</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.5465</td>\n",
       "      <td>0.5493</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1.0088</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>2.2222</td>\n",
       "      <td>2.2853</td>\n",
       "      <td>0.4960</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.5715</td>\n",
       "      <td>0.5650</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.5526</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.0008</td>\n",
       "      <td>0.9840</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>2.2016</td>\n",
       "      <td>2.2950</td>\n",
       "      <td>0.5442</td>\n",
       "      <td>0.5481</td>\n",
       "      <td>0.5554</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.5658</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.5465</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.5582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.4417</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.5193</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>0.5157</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5414</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.5577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.4362</td>\n",
       "      <td>0.4602</td>\n",
       "      <td>0.4322</td>\n",
       "      <td>0.8658</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.5399</td>\n",
       "      <td>0.5412</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.5576</td>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.5439</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.5451</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.1169</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>0.4069</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>0.4884</td>\n",
       "      <td>0.5183</td>\n",
       "      <td>0.5381</td>\n",
       "      <td>0.5506</td>\n",
       "      <td>0.5594</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0220</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>2.1756</td>\n",
       "      <td>2.2922</td>\n",
       "      <td>0.5257</td>\n",
       "      <td>0.5486</td>\n",
       "      <td>0.5550</td>\n",
       "      <td>0.5746</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>0.5459</td>\n",
       "      <td>0.5489</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1.0317</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>2.2412</td>\n",
       "      <td>2.2881</td>\n",
       "      <td>0.4962</td>\n",
       "      <td>0.5293</td>\n",
       "      <td>0.5523</td>\n",
       "      <td>0.5688</td>\n",
       "      <td>0.5599</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.5490</td>\n",
       "      <td>0.5517</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.5075</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.4968</td>\n",
       "      <td>0.5377</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.5407</td>\n",
       "      <td>0.5421</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>0.5575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.0621</td>\n",
       "      <td>0.9936</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>2.3020</td>\n",
       "      <td>2.3103</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.5514</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.5327</td>\n",
       "      <td>0.5467</td>\n",
       "      <td>0.5494</td>\n",
       "      <td>0.5520</td>\n",
       "      <td>0.5584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.1039</td>\n",
       "      <td>0.4224</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.4088</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.4904</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5559</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.5180</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.5480</td>\n",
       "      <td>0.5579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.6923</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>0.3962</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.5122</td>\n",
       "      <td>0.5283</td>\n",
       "      <td>0.5259</td>\n",
       "      <td>0.5248</td>\n",
       "      <td>0.5476</td>\n",
       "      <td>0.5432</td>\n",
       "      <td>0.5428</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.5581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0117</td>\n",
       "      <td>0.9846</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>0.9910</td>\n",
       "      <td>2.0687</td>\n",
       "      <td>2.2839</td>\n",
       "      <td>0.5374</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.5532</td>\n",
       "      <td>0.5689</td>\n",
       "      <td>0.5623</td>\n",
       "      <td>0.5449</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>0.5497</td>\n",
       "      <td>0.5522</td>\n",
       "      <td>0.5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.7839</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>0.3776</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.5245</td>\n",
       "      <td>0.5211</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.5431</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.5424</td>\n",
       "      <td>0.5444</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.5580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.0337</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>2.2621</td>\n",
       "      <td>2.3034</td>\n",
       "      <td>0.5052</td>\n",
       "      <td>0.5367</td>\n",
       "      <td>0.5538</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.5647</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>0.5487</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.9943</td>\n",
       "      <td>0.9922</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>2.2799</td>\n",
       "      <td>2.2908</td>\n",
       "      <td>0.5055</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.5519</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.5642</td>\n",
       "      <td>0.5329</td>\n",
       "      <td>0.5469</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>0.5521</td>\n",
       "      <td>0.5504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      20      40      60      80     100    hi10    hi30    hi50  \\\n",
       "28  0.9037  0.7209  0.6564  0.2959  0.0197  0.0376  0.4817  0.5033  0.5158   \n",
       "29  0.9622  0.8487  0.6007  0.4016  0.0306  0.0278  0.4782  0.5000  0.5093   \n",
       "30  0.9930  0.9915  0.9419  0.9952  2.2609  2.3048  0.5427  0.5485  0.5533   \n",
       "31  1.0003  0.8832  0.7028  0.3013 -0.0823  0.1933  0.4941  0.5140  0.5134   \n",
       "32  1.0411  0.9980  0.9241  1.0000  0.0306  0.0000  0.5224  0.5057  0.4895   \n",
       "33  0.9632  0.8229  0.4625  0.1315 -0.0053  0.0455  0.4878  0.5126  0.5113   \n",
       "34  0.9273  0.7657  0.5313  0.2329  0.1094  0.0042  0.4998  0.5168  0.5207   \n",
       "35  1.0734  0.9845  0.9123  0.9838  2.2674  2.2797  0.5065  0.5344  0.5530   \n",
       "36  0.1729  0.4900  0.5016  0.4880  1.1104  1.0348  0.5196  0.5396  0.5437   \n",
       "37  1.0342  0.9921  0.9399  0.9940  2.1909  2.3048  0.5344  0.5477  0.5537   \n",
       "38  1.0058  0.9787  0.8976  0.9844  2.2853  2.2737  0.5259  0.5486  0.5531   \n",
       "39  0.9936  0.9842  0.9198  0.9934  2.2772  2.2709  0.5055  0.5295  0.5509   \n",
       "40  0.9628  0.6962  0.4609  0.1627  0.0267  0.1154  0.5112  0.5253  0.5207   \n",
       "41  1.0419  0.9860  0.9185  0.9844  2.2208  2.2658  0.5247  0.5474  0.5538   \n",
       "42  1.0621  0.9924  0.9154  0.9928  2.2155  2.2617  0.5472  0.5506  0.5567   \n",
       "..     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "78  1.0088  0.9870  0.9357  0.9928  2.2222  2.2853  0.4960  0.5480  0.5530   \n",
       "79  1.0008  0.9840  0.9200  0.9892  2.2016  2.2950  0.5442  0.5481  0.5554   \n",
       "80  0.9975  0.8044  0.4417  0.1789  0.0223  0.0445  0.5193  0.5214  0.5157   \n",
       "81  0.0666  0.4362  0.4602  0.4322  0.8658  1.0056  0.5399  0.5412  0.5450   \n",
       "82  0.1169  0.3907  0.4069  0.3830  0.9319  0.8415  0.4884  0.5183  0.5381   \n",
       "83  1.0220  0.9917  0.9257  0.9898  2.1756  2.2922  0.5257  0.5486  0.5550   \n",
       "84  1.0317  0.9845  0.8849  0.9862  2.2412  2.2881  0.4962  0.5293  0.5523   \n",
       "85  0.9598  0.6521  0.2859  0.1110  0.0056  0.0389  0.4889  0.5075  0.5125   \n",
       "86  1.0621  0.9936  0.9135  0.9898  2.3020  2.3103  0.5250  0.5476  0.5514   \n",
       "87  0.1039  0.4224  0.4199  0.4088  0.9767  0.8638  0.4904  0.5206  0.5423   \n",
       "88  0.9273  0.6923  0.5318  0.3962  0.0911  0.0974  0.5122  0.5283  0.5259   \n",
       "89  1.0117  0.9846  0.9167  0.9910  2.0687  2.2839  0.5374  0.5483  0.5532   \n",
       "90  0.9331  0.7839  0.5396  0.3776  0.0948  0.0348  0.5292  0.5245  0.5211   \n",
       "95  1.0337  0.9883  0.8952  0.9922  2.2621  2.3034  0.5052  0.5367  0.5538   \n",
       "97  0.9943  0.9922  0.8844  0.9850  2.2799  2.2908  0.5055  0.5330  0.5519   \n",
       "\n",
       "      hi70    hi90    lo10    lo30    lo50    lo70    lo90  \n",
       "28  0.5072  0.5448  0.5437  0.5437  0.5455  0.5494  0.5499  \n",
       "29  0.4956  0.5421  0.5062  0.5424  0.5442  0.5484  0.5485  \n",
       "30  0.5716  0.5650  0.5452  0.5469  0.5492  0.5519  0.5497  \n",
       "31  0.5127  0.5478  0.5438  0.5438  0.5460  0.5495  0.5527  \n",
       "32  0.4930  0.5314  0.5113  0.4289  0.3545  0.3233  0.4434  \n",
       "33  0.4950  0.5388  0.5306  0.5412  0.5433  0.5471  0.5493  \n",
       "34  0.5147  0.5441  0.5435  0.5427  0.5447  0.5539  0.5579  \n",
       "35  0.5726  0.5659  0.5072  0.5459  0.5485  0.5511  0.5579  \n",
       "36  0.5557  0.5605  0.5436  0.5426  0.5445  0.5479  0.5576  \n",
       "37  0.5704  0.5602  0.5448  0.5464  0.5492  0.5509  0.5580  \n",
       "38  0.5710  0.5591  0.5387  0.5460  0.5491  0.5518  0.5583  \n",
       "39  0.5854  0.5648  0.5449  0.5467  0.5493  0.5515  0.5586  \n",
       "40  0.5137  0.5420  0.5433  0.5423  0.5440  0.5481  0.5574  \n",
       "41  0.5717  0.5622  0.5448  0.5463  0.5492  0.5520  0.5585  \n",
       "42  0.5727  0.5604  0.5451  0.5465  0.5493  0.5522  0.5579  \n",
       "..     ...     ...     ...     ...     ...     ...     ...  \n",
       "78  0.5715  0.5650  0.5451  0.5464  0.5492  0.5526  0.5586  \n",
       "79  0.5745  0.5658  0.5450  0.5465  0.5494  0.5522  0.5582  \n",
       "80  0.5008  0.5375  0.5431  0.5414  0.5432  0.5474  0.5577  \n",
       "81  0.5576  0.5568  0.5439  0.5434  0.5451  0.5489  0.5579  \n",
       "82  0.5506  0.5594  0.5433  0.5417  0.5428  0.5466  0.5575  \n",
       "83  0.5746  0.5609  0.5437  0.5459  0.5489  0.5516  0.5580  \n",
       "84  0.5688  0.5599  0.5074  0.5464  0.5490  0.5517  0.5584  \n",
       "85  0.4968  0.5377  0.5180  0.5407  0.5421  0.5462  0.5575  \n",
       "86  0.5684  0.5580  0.5327  0.5467  0.5494  0.5520  0.5584  \n",
       "87  0.5559  0.5620  0.5180  0.5428  0.5444  0.5480  0.5579  \n",
       "88  0.5248  0.5476  0.5432  0.5428  0.5445  0.5542  0.5581  \n",
       "89  0.5689  0.5623  0.5449  0.5464  0.5497  0.5522  0.5494  \n",
       "90  0.5179  0.5431  0.5433  0.5424  0.5444  0.5542  0.5580  \n",
       "95  0.5714  0.5647  0.5201  0.5461  0.5487  0.5516  0.5586  \n",
       "97  0.5700  0.5642  0.5329  0.5469  0.5501  0.5521  0.5504  \n",
       "\n",
       "[61 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.opt.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000064\n",
      "         Iterations: 296\n",
      "         Function evaluations: 794\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013252\n",
      "         Iterations: 831\n",
      "         Function evaluations: 2219\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.593832\n",
      "         Iterations: 181\n",
      "         Function evaluations: 466\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.664566\n",
      "         Iterations: 274\n",
      "         Function evaluations: 763\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000087\n",
      "         Iterations: 279\n",
      "         Function evaluations: 753\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.107719\n",
      "         Iterations: 278\n",
      "         Function evaluations: 708\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.807004\n",
      "         Iterations: 161\n",
      "         Function evaluations: 429\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.840478\n",
      "         Iterations: 570\n",
      "         Function evaluations: 1523\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000115\n",
      "         Iterations: 705\n",
      "         Function evaluations: 1913\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.014792\n",
      "         Iterations: 293\n",
      "         Function evaluations: 765\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000019\n",
      "         Iterations: 334\n",
      "         Function evaluations: 846\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.199840\n",
      "         Iterations: 380\n",
      "         Function evaluations: 1068\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 176\n",
      "         Function evaluations: 455\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.717606\n",
      "         Iterations: 374\n",
      "         Function evaluations: 1005\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.841448\n",
      "         Iterations: 278\n",
      "         Function evaluations: 730\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.120959\n",
      "         Iterations: 359\n",
      "         Function evaluations: 949\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.728341\n",
      "         Iterations: 217\n",
      "         Function evaluations: 579\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.024142\n",
      "         Iterations: 368\n",
      "         Function evaluations: 1019\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000082\n",
      "         Iterations: 187\n",
      "         Function evaluations: 492\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.734400\n",
      "         Iterations: 258\n",
      "         Function evaluations: 736\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.533202\n",
      "         Iterations: 315\n",
      "         Function evaluations: 883\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.851752\n",
      "         Iterations: 259\n",
      "         Function evaluations: 698\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.527569\n",
      "         Iterations: 221\n",
      "         Function evaluations: 622\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000027\n",
      "         Iterations: 165\n",
      "         Function evaluations: 450\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.601645\n",
      "         Iterations: 451\n",
      "         Function evaluations: 1211\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000106\n",
      "         Iterations: 296\n",
      "         Function evaluations: 756\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010835\n",
      "         Iterations: 309\n",
      "         Function evaluations: 801\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000139\n",
      "         Iterations: 188\n",
      "         Function evaluations: 487\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005656\n",
      "         Iterations: 295\n",
      "         Function evaluations: 763\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000054\n",
      "         Iterations: 217\n",
      "         Function evaluations: 531\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.889922\n",
      "         Iterations: 167\n",
      "         Function evaluations: 467\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.592652\n",
      "         Iterations: 1004\n",
      "         Function evaluations: 2757\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000172\n",
      "         Iterations: 180\n",
      "         Function evaluations: 470\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.013323\n",
      "         Iterations: 577\n",
      "         Function evaluations: 1534\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650031\n",
      "         Iterations: 211\n",
      "         Function evaluations: 543\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.411187\n",
      "         Iterations: 788\n",
      "         Function evaluations: 2165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000035\n",
      "         Iterations: 192\n",
      "         Function evaluations: 491\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.584036\n",
      "         Iterations: 320\n",
      "         Function evaluations: 815\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001212\n",
      "         Iterations: 294\n",
      "         Function evaluations: 767\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.571983\n",
      "         Iterations: 244\n",
      "         Function evaluations: 674\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636052\n",
      "         Iterations: 164\n",
      "         Function evaluations: 437\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 9.011182\n",
      "         Iterations: 353\n",
      "         Function evaluations: 976\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000132\n",
      "         Iterations: 401\n",
      "         Function evaluations: 1043\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.280999\n",
      "         Iterations: 741\n",
      "         Function evaluations: 2020\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004366\n",
      "         Iterations: 316\n",
      "         Function evaluations: 787\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.896295\n",
      "         Iterations: 161\n",
      "         Function evaluations: 436\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000069\n",
      "         Iterations: 407\n",
      "         Function evaluations: 1056\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.099265\n",
      "         Iterations: 1041\n",
      "         Function evaluations: 2964\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.432158\n",
      "         Iterations: 440\n",
      "         Function evaluations: 1177\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.650500\n",
      "         Iterations: 508\n",
      "         Function evaluations: 1386\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.595833\n",
      "         Iterations: 201\n",
      "         Function evaluations: 581\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000069\n",
      "         Iterations: 391\n",
      "         Function evaluations: 1092\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.369001\n",
      "         Iterations: 226\n",
      "         Function evaluations: 613\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.045752\n",
      "         Iterations: 306\n",
      "         Function evaluations: 755\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.747025\n",
      "         Iterations: 155\n",
      "         Function evaluations: 415\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.212977\n",
      "         Iterations: 837\n",
      "         Function evaluations: 2279\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000075\n",
      "         Iterations: 179\n",
      "         Function evaluations: 471\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.322924\n",
      "         Iterations: 316\n",
      "         Function evaluations: 821\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.839932\n",
      "         Iterations: 167\n",
      "         Function evaluations: 450\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.513015\n",
      "         Iterations: 254\n",
      "         Function evaluations: 679\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000061\n",
      "         Iterations: 198\n",
      "         Function evaluations: 506\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.214153\n",
      "         Iterations: 1165\n",
      "         Function evaluations: 3119\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 9.911567\n",
      "         Iterations: 486\n",
      "         Function evaluations: 1411\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000078\n",
      "         Iterations: 177\n",
      "         Function evaluations: 465\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010348\n",
      "         Iterations: 418\n",
      "         Function evaluations: 1124\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.715344\n",
      "         Iterations: 335\n",
      "         Function evaluations: 899\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000046\n",
      "         Iterations: 197\n",
      "         Function evaluations: 493\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 1.146552\n",
      "         Iterations: 265\n",
      "         Function evaluations: 752\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 12.100733\n",
      "         Iterations: 328\n",
      "         Function evaluations: 867\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000121\n",
      "         Iterations: 196\n",
      "         Function evaluations: 500\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.035529\n",
      "         Iterations: 336\n",
      "         Function evaluations: 800\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000104\n",
      "         Iterations: 751\n",
      "         Function evaluations: 1971\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.253341\n",
      "         Iterations: 249\n",
      "         Function evaluations: 710\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.685681\n",
      "         Iterations: 162\n",
      "         Function evaluations: 436\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.486489\n",
      "         Iterations: 301\n",
      "         Function evaluations: 836\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.720546\n",
      "         Iterations: 224\n",
      "         Function evaluations: 587\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.499486\n",
      "         Iterations: 766\n",
      "         Function evaluations: 2158\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005488\n",
      "         Iterations: 356\n",
      "         Function evaluations: 864\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000065\n",
      "         Iterations: 200\n",
      "         Function evaluations: 521\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000012\n",
      "         Iterations: 378\n",
      "         Function evaluations: 1045\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.702376\n",
      "         Iterations: 155\n",
      "         Function evaluations: 415\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.959315\n",
      "         Iterations: 654\n",
      "         Function evaluations: 1742\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.127967\n",
      "         Iterations: 225\n",
      "         Function evaluations: 602\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000047\n",
      "         Iterations: 196\n",
      "         Function evaluations: 529\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.490252\n",
      "         Iterations: 373\n",
      "         Function evaluations: 1068\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000086\n",
      "         Iterations: 378\n",
      "         Function evaluations: 1047\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 2.183350\n",
      "         Iterations: 351\n",
      "         Function evaluations: 969\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 228\n",
      "         Function evaluations: 592\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.673063\n",
      "         Iterations: 216\n",
      "         Function evaluations: 584\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 9.407311\n",
      "         Iterations: 970\n",
      "         Function evaluations: 2746\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000104\n",
      "         Iterations: 181\n",
      "         Function evaluations: 479\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003268\n",
      "         Iterations: 296\n",
      "         Function evaluations: 754\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.954169\n",
      "         Iterations: 465\n",
      "         Function evaluations: 1239\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.339583\n",
      "         Iterations: 244\n",
      "         Function evaluations: 701\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.921823\n",
      "         Iterations: 436\n",
      "         Function evaluations: 1176\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 11.453808\n",
      "         Iterations: 239\n",
      "         Function evaluations: 653\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-68dbe65363ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/build.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, save, savepth, ntrials, ftol, xtol, maxfev, niter, log_fits, disp, prob)\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdframes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepends_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdepends_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpc_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpc_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m             \u001b[1;31m# get residuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresidual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m(self, save, savepth)\u001b[0m\n\u001b[0;32m     64\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                   \u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__indx_optimize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "m.optimize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

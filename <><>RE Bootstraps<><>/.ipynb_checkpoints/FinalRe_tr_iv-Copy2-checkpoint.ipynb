{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sab vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radd import build, vis\n",
    "from radd.toolbox import analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyze.finfo_to_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('xsab_v')\n",
    "os.chdir('xsab_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0.54012,\n",
       " 'ssv': -1.094068,\n",
       " 'tr': 0.18531,\n",
       " 'v': 1.20882,\n",
       " 'xb': 0.84012,\n",
       " 'z': 0.04201492599481827}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.inits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inits = {'a': 0.44470913,\n",
    " 'ssv': -0.9415135,\n",
    " 'tr': 0.30481227,\n",
    " 'v': 1.07049551,\n",
    " 'xb': 1.5,\n",
    " 'z': 0.15049553}\n",
    "popt={'a': 0.54012, 'z': 0.042014925994818271, 'v': 1.20882, 'xb': .84012, 'ssv': -1.094068, 'tr': 0.18531}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sab_inits={'a': array([ 0.48227]), 'sso': 0.01804612312742325, 'v': array([ 1.18368]), 'xb': array([ 1.43943]), 'ssv': -0.93274357892086091, 'tr': array([ 0.21019])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m=build.Model(data=redata, kind='xsab', depends_on={'v':'Cond'}, inits=sab_inits)\n",
    "m.inits=popt\n",
    "fidf=pd.DataFrame(columns=m.dframes['fitinfo'].columns, index=np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basinhopping step 0: f 0.0822088\n",
      "basinhopping step 1: f 0.762671 trial_f 0.762671 accepted 1  lowest_f 0.0822088\n",
      "basinhopping step 2: f 0.762671 trial_f 1.51903 accepted 0  lowest_f 0.0822088\n",
      "basinhopping step 3: f 0.315025 trial_f 0.315025 accepted 1  lowest_f 0.0822088\n",
      "basinhopping step 4: f 0.143398 trial_f 0.143398 accepted 1  lowest_f 0.0822088\n",
      "basinhopping step 5: f 0.00921906 trial_f 0.00921906 accepted 1  lowest_f 0.00921906\n",
      "found new global minimum on step 5 with function value 0.00921906\n",
      "basinhopping step 6: f 0.10417 trial_f 0.10417 accepted 1  lowest_f 0.00921906\n",
      "basinhopping step 7: f 0.202767 trial_f 0.202767 accepted 1  lowest_f 0.00921906\n",
      "basinhopping step 8: f 0.202767 trial_f 1.122 accepted 0  lowest_f 0.00921906\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 9: f 0.070871 trial_f 0.070871 accepted 1  lowest_f 0.00921906\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 10: f 0.0341348 trial_f 0.0341348 accepted 1  lowest_f 0.00921906\n",
      "basinhopping step 11: f 0.116983 trial_f 0.116983 accepted 1  lowest_f 0.00921906\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 12: f 0.116983 trial_f 1.09817 accepted 0  lowest_f 0.00921906\n",
      "basinhopping step 13: f 0.0133503 trial_f 0.0133503 accepted 1  lowest_f 0.00921906\n",
      "basinhopping step 14: f 0.00494169 trial_f 0.00494169 accepted 1  lowest_f 0.00494169\n",
      "found new global minimum on step 14 with function value 0.00494169\n",
      "basinhopping step 15: f 0.0315679 trial_f 0.0315679 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 16: f 0.372403 trial_f 0.372403 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 17: f 0.00630724 trial_f 0.00630724 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 18: f 0.00630724 trial_f 0.295618 accepted 0  lowest_f 0.00494169\n",
      "basinhopping step 19: f 0.119621 trial_f 0.119621 accepted 1  lowest_f 0.00494169\n",
      "adaptive stepsize: acceptance rate 0.750000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 0.70635 trial_f 0.70635 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 21: f 0.70635 trial_f 2.02147 accepted 0  lowest_f 0.00494169\n",
      "basinhopping step 22: f 0.70635 trial_f 1.60347 accepted 0  lowest_f 0.00494169\n",
      "basinhopping step 23: f 0.564794 trial_f 0.564794 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 24: f 0.179593 trial_f 0.179593 accepted 1  lowest_f 0.00494169\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 25: f 0.179593 trial_f 0.471987 accepted 0  lowest_f 0.00494169\n",
      "basinhopping step 26: f 0.0245676 trial_f 0.0245676 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 27: f 0.94924 trial_f 0.94924 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 28: f 1.0541 trial_f 1.0541 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 29: f 1.06473 trial_f 1.06473 accepted 1  lowest_f 0.00494169\n",
      "adaptive stepsize: acceptance rate 0.733333 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 0.988448 trial_f 0.988448 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 31: f 0.988448 trial_f 2.10402 accepted 0  lowest_f 0.00494169\n",
      "basinhopping step 32: f 0.799817 trial_f 0.799817 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 33: f 0.172189 trial_f 0.172189 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 34: f 0.106 trial_f 0.106 accepted 1  lowest_f 0.00494169\n",
      "basinhopping step 35: f 0.10871 trial_f 0.10871 accepted 1  lowest_f 0.00494169\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000004\n",
      "         Iterations: 58\n",
      "         Function evaluations: 154\n",
      "basinhopping step 0: f 2.87527\n",
      "basinhopping step 1: f 2.64373 trial_f 2.64373 accepted 1  lowest_f 2.64373\n",
      "found new global minimum on step 1 with function value 2.64373\n",
      "basinhopping step 2: f 2.3427 trial_f 2.3427 accepted 1  lowest_f 2.3427\n",
      "found new global minimum on step 2 with function value 2.3427\n",
      "basinhopping step 3: f 2.31518 trial_f 2.31518 accepted 1  lowest_f 2.31518\n",
      "found new global minimum on step 3 with function value 2.31518\n",
      "basinhopping step 4: f 2.60146 trial_f 2.60146 accepted 1  lowest_f 2.31518\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 2.56255 trial_f 2.56255 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 6: f 2.51866 trial_f 2.51866 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 7: f 2.80163 trial_f 2.80163 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 8: f 2.84525 trial_f 2.84525 accepted 1  lowest_f 2.31518\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 9: f 2.75319 trial_f 2.75319 accepted 1  lowest_f 2.31518\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 10: f 3.02001 trial_f 3.02001 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 11: f 2.96552 trial_f 2.96552 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 12: f 2.72313 trial_f 2.72313 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 13: f 2.50053 trial_f 2.50053 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 14: f 2.83733 trial_f 2.83733 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 15: f 2.83733 trial_f 3.08966 accepted 0  lowest_f 2.31518\n",
      "basinhopping step 16: f 2.72018 trial_f 2.72018 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 17: f 2.49176 trial_f 2.49176 accepted 1  lowest_f 2.31518\n",
      "basinhopping step 18: f 2.27752 trial_f 2.27752 accepted 1  lowest_f 2.27752\n",
      "found new global minimum on step 18 with function value 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 19: f 2.45573 trial_f 2.45573 accepted 1  lowest_f 2.27752\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 20: f 2.48347 trial_f 2.48347 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 21: f 2.76572 trial_f 2.76572 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 22: f 3.06164 trial_f 3.06164 accepted 1  lowest_f 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 23: f 2.97923 trial_f 2.97923 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 24: f 3.00338 trial_f 3.00338 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 25: f 2.84589 trial_f 2.84589 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 26: f 2.6022 trial_f 2.6022 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 27: f 2.51389 trial_f 2.51389 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 28: f 2.51389 trial_f 2.88273 accepted 0  lowest_f 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 29: f 2.55955 trial_f 2.55955 accepted 1  lowest_f 2.27752\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 2.86754 trial_f 2.86754 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 31: f 2.50247 trial_f 2.50247 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 32: f 2.80564 trial_f 2.80564 accepted 1  lowest_f 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 33: f 2.40394 trial_f 2.40394 accepted 1  lowest_f 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 34: f 2.56368 trial_f 2.56368 accepted 1  lowest_f 2.27752\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 35: f 2.67452 trial_f 2.67452 accepted 1  lowest_f 2.27752\n",
      "basinhopping step 36: f 2.2629 trial_f 2.2629 accepted 1  lowest_f 2.2629\n",
      "found new global minimum on step 36 with function value 2.2629\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 37: f 2.47113 trial_f 2.47113 accepted 1  lowest_f 2.2629\n",
      "basinhopping step 38: f 2.66566 trial_f 2.66566 accepted 1  lowest_f 2.2629\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 39: f 2.57873 trial_f 2.57873 accepted 1  lowest_f 2.2629\n",
      "adaptive stepsize: acceptance rate 0.925000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "basinhopping step 40: f 2.25854 trial_f 2.25854 accepted 1  lowest_f 2.25854\n",
      "found new global minimum on step 40 with function value 2.25854\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 41: f 2.19087 trial_f 2.19087 accepted 1  lowest_f 2.19087\n",
      "found new global minimum on step 41 with function value 2.19087\n",
      "basinhopping step 42: f 1.94313 trial_f 1.94313 accepted 1  lowest_f 1.94313\n",
      "found new global minimum on step 42 with function value 1.94313\n",
      "basinhopping step 43: f 1.87529 trial_f 1.87529 accepted 1  lowest_f 1.87529\n",
      "found new global minimum on step 43 with function value 1.87529\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 44: f 1.75513 trial_f 1.75513 accepted 1  lowest_f 1.75513\n",
      "found new global minimum on step 44 with function value 1.75513\n",
      "basinhopping step 45: f 1.76642 trial_f 1.76642 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 46: f 1.7714 trial_f 1.7714 accepted 1  lowest_f 1.75513\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 47: f 1.77819 trial_f 1.77819 accepted 1  lowest_f 1.75513\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 48: f 1.84026 trial_f 1.84026 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 49: f 1.90214 trial_f 1.90214 accepted 1  lowest_f 1.75513\n",
      "adaptive stepsize: acceptance rate 0.940000 target 0.500000 new stepsize 0.0846754 old stepsize 0.0762079\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 50: f 1.90214 trial_f 2.11081 accepted 0  lowest_f 1.75513\n",
      "basinhopping step 51: f 1.78923 trial_f 1.78923 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 52: f 1.90213 trial_f 1.90213 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 53: f 1.96309 trial_f 1.96309 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 54: f 1.89899 trial_f 1.89899 accepted 1  lowest_f 1.75513\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 55: f 1.95671 trial_f 1.95671 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 56: f 2.0727 trial_f 2.0727 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 57: f 2.04064 trial_f 2.04064 accepted 1  lowest_f 1.75513\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 58: f 1.93637 trial_f 1.93637 accepted 1  lowest_f 1.75513\n",
      "basinhopping step 59: f 1.75961 trial_f 1.75961 accepted 1  lowest_f 1.75513\n",
      "adaptive stepsize: acceptance rate 0.933333 target 0.500000 new stepsize 0.0940838 old stepsize 0.0846754\n",
      "basinhopping step 60: f 1.75393 trial_f 1.75393 accepted 1  lowest_f 1.75393\n",
      "found new global minimum on step 60 with function value 1.75393\n",
      "basinhopping step 61: f 1.92606 trial_f 1.92606 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 62: f 1.7765 trial_f 1.7765 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 63: f 1.87547 trial_f 1.87547 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 64: f 2.04465 trial_f 2.04465 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 65: f 1.83835 trial_f 1.83835 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 66: f 1.84579 trial_f 1.84579 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 67: f 1.76964 trial_f 1.76964 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 68: f 1.89728 trial_f 1.89728 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 69: f 1.88491 trial_f 1.88491 accepted 1  lowest_f 1.75393\n",
      "adaptive stepsize: acceptance rate 0.942857 target 0.500000 new stepsize 0.104538 old stepsize 0.0940838\n",
      "basinhopping step 70: f 1.77814 trial_f 1.77814 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 71: f 1.85525 trial_f 1.85525 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 72: f 1.77434 trial_f 1.77434 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 73: f 1.76637 trial_f 1.76637 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 74: f 1.78618 trial_f 1.78618 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 75: f 1.75449 trial_f 1.75449 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 76: f 1.77618 trial_f 1.77618 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 77: f 1.76994 trial_f 1.76994 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 78: f 1.75838 trial_f 1.75838 accepted 1  lowest_f 1.75393\n",
      "basinhopping step 79: f 1.75838 trial_f 1.87643 accepted 0  lowest_f 1.75393\n",
      "adaptive stepsize: acceptance rate 0.937500 target 0.500000 new stepsize 0.116153 old stepsize 0.104538\n",
      "basinhopping step 80: f 1.75661 trial_f 1.75661 accepted 1  lowest_f 1.75393\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 0: f 14.0088\n",
      "basinhopping step 1: f 14.0088 trial_f 15.2618 accepted 0  lowest_f 14.0088\n",
      "basinhopping step 2: f 15.2835 trial_f 15.2835 accepted 1  lowest_f 14.0088\n",
      "basinhopping step 3: f 14.3117 trial_f 14.3117 accepted 1  lowest_f 14.0088\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 4: f 14.0826 trial_f 14.0826 accepted 1  lowest_f 14.0088\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 14.0826 trial_f 14.9523 accepted 0  lowest_f 14.0088\n",
      "basinhopping step 6: f 14.4896 trial_f 14.4896 accepted 1  lowest_f 14.0088\n",
      "basinhopping step 7: f 13.5847 trial_f 13.5847 accepted 1  lowest_f 13.5847\n",
      "found new global minimum on step 7 with function value 13.5847\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 8: f 13.5847 trial_f 14.6282 accepted 0  lowest_f 13.5847\n",
      "basinhopping step 9: f 14.6887 trial_f 14.6887 accepted 1  lowest_f 13.5847\n",
      "adaptive stepsize: acceptance rate 0.600000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 13.9878 trial_f 13.9878 accepted 1  lowest_f 13.5847\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 11: f 13.4593 trial_f 13.4593 accepted 1  lowest_f 13.4593\n",
      "found new global minimum on step 11 with function value 13.4593\n",
      "basinhopping step 12: f 14.2872 trial_f 14.2872 accepted 1  lowest_f 13.4593\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 13: f 13.7435 trial_f 13.7435 accepted 1  lowest_f 13.4593\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 14: f 13.7874 trial_f 13.7874 accepted 1  lowest_f 13.4593\n",
      "basinhopping step 15: f 12.3504 trial_f 12.3504 accepted 1  lowest_f 12.3504\n",
      "found new global minimum on step 15 with function value 12.3504\n",
      "basinhopping step 16: f 11.2242 trial_f 11.2242 accepted 1  lowest_f 11.2242\n",
      "found new global minimum on step 16 with function value 11.2242\n",
      "basinhopping step 17: f 11.5141 trial_f 11.5141 accepted 1  lowest_f 11.2242\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 18: f 11.2234 trial_f 11.2234 accepted 1  lowest_f 11.2234\n",
      "found new global minimum on step 18 with function value 11.2234\n",
      "basinhopping step 19: f 11.3694 trial_f 11.3694 accepted 1  lowest_f 11.2234\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 11.3694 trial_f 12.71 accepted 0  lowest_f 11.2234\n",
      "basinhopping step 21: f 10.7629 trial_f 10.7629 accepted 1  lowest_f 10.7629\n",
      "found new global minimum on step 21 with function value 10.7629\n",
      "basinhopping step 22: f 10.9738 trial_f 10.9738 accepted 1  lowest_f 10.7629\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 23: f 12.1861 trial_f 12.1861 accepted 1  lowest_f 10.7629\n",
      "basinhopping step 24: f 12.082 trial_f 12.082 accepted 1  lowest_f 10.7629\n",
      "basinhopping step 25: f 11.0721 trial_f 11.0721 accepted 1  lowest_f 10.7629\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 26: f 10.5219 trial_f 10.5219 accepted 1  lowest_f 10.5219\n",
      "found new global minimum on step 26 with function value 10.5219\n",
      "basinhopping step 27: f 10.5977 trial_f 10.5977 accepted 1  lowest_f 10.5219\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 28: f 10.3032 trial_f 10.3032 accepted 1  lowest_f 10.3032\n",
      "found new global minimum on step 28 with function value 10.3032\n",
      "basinhopping step 29: f 10.3961 trial_f 10.3961 accepted 1  lowest_f 10.3032\n",
      "adaptive stepsize: acceptance rate 0.833333 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 10.1586 trial_f 10.1586 accepted 1  lowest_f 10.1586\n",
      "found new global minimum on step 30 with function value 10.1586\n",
      "basinhopping step 31: f 10.5345 trial_f 10.5345 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 32: f 10.5345 trial_f 11.3752 accepted 0  lowest_f 10.1586\n",
      "basinhopping step 33: f 10.2657 trial_f 10.2657 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 34: f 10.5483 trial_f 10.5483 accepted 1  lowest_f 10.1586\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 35: f 10.5183 trial_f 10.5183 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 36: f 10.2773 trial_f 10.2773 accepted 1  lowest_f 10.1586\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 37: f 10.6769 trial_f 10.6769 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 38: f 10.6769 trial_f 12.1815 accepted 0  lowest_f 10.1586\n",
      "basinhopping step 39: f 11.7456 trial_f 11.7456 accepted 1  lowest_f 10.1586\n",
      "adaptive stepsize: acceptance rate 0.825000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 40: f 11.0897 trial_f 11.0897 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 41: f 11.0897 trial_f 12.9749 accepted 0  lowest_f 10.1586\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 42: f 11.1151 trial_f 11.1151 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 43: f 12.3682 trial_f 12.3682 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 44: f 12.3094 trial_f 12.3094 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 45: f 12.3094 trial_f 13.6072 accepted 0  lowest_f 10.1586\n",
      "basinhopping step 46: f 12.3094 trial_f 13.1391 accepted 0  lowest_f 10.1586\n",
      "basinhopping step 47: f 12.3094 trial_f 13.5209 accepted 0  lowest_f 10.1586\n",
      "basinhopping step 48: f 12.6598 trial_f 12.6598 accepted 1  lowest_f 10.1586\n",
      "basinhopping step 49: f 12.6598 trial_f 13.3672 accepted 0  lowest_f 10.1586\n",
      "adaptive stepsize: acceptance rate 0.760000 target 0.500000 new stepsize 0.0846754 old stepsize 0.0762079\n",
      "basinhopping step 50: f 12.705 trial_f 12.705 accepted 1  lowest_f 10.1586\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4aeae40de3a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'full'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m       \u001b[1;31m#finfo_list.append(m.fitinfo.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m       \u001b[1;31m#x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/build.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, save, savepth, ntrials, tol, maxfev, niter, disp, prob, multiopt, stage, inits, y)\u001b[0m\n\u001b[0;32m     74\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                   \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m(self, save, savepth)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'average'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__opt_routine__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'subjects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bootstrap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__indx_optimize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36m__opt_routine__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mflat_yh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_fi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# STAGE 2 (Nudge/BasinHopping) & STAGE 3 (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_conditional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_conditional\u001b[1;34m(self, p, y, precond)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprecond\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiopt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                   \u001b[1;31m# pretune conditional parameters (1/time)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                   \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_basin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;31m# STAGE 3: (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36msingle_basin\u001b[1;34m(self, p, disp, interval, niter, stepsize, nsuccess)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__update__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_flat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                   \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasinhopping_minimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimizer_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter_success\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                   \u001b[0mxbasin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mbasinhopping\u001b[1;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success)\u001b[0m\n\u001b[0;32m    612\u001b[0m                \" successfully\"]\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mone_cycle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mxtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menergy_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monte_carlo_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m_monte_carlo_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# do a local minimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mminres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_after_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mx_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0menergy_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x0)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[1;32m--> 447\u001b[1;33m                              **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cobyla'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36m_minimize_tnc\u001b[1;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    407\u001b[0m                                         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxCGit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                         \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepmx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                                         xtol, pgtol, rescale, callback)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mfunv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjacv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapprox_fprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mapprox_fprime\u001b[1;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \"\"\"\n\u001b[1;32m--> 618\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36mbasinhopping_minimizer\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.e5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim_fx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__iter__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36msimulate_radd\u001b[1;34m(self, p, analyze)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;31m# INITIALIZE DVs FROM DVg(t=SSD)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0minit_ss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDVg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTs\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mTg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mTs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mDVs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_ss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mPs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze_reactive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDVg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDVs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "      m.optimize(stage='full', multiopt=True)      \n",
    "      #finfo_list.append(m.fitinfo.T) \n",
    "      #x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\n",
    "      for c in cols:\n",
    "            fidf.loc[i, c]=m.fitinfo[c]\n",
    "      fidf.to_csv(\"finfo_xsab_v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = {'a_bsl':   0.529353,\n",
    "'a_pnl': 0.553150,\n",
    "'xb': 0.817502,\n",
    "'ssv': -1.104875,\n",
    "'tr': 0.185667,\n",
    "'v': 1.208608,\n",
    "'z': 0.0436727}\n",
    "\n",
    "x2 = {'a': 0.3964024,\n",
    " 'ssv': -0.7881214,\n",
    " 'tr': 0.2915253,\n",
    " 'v_bsl': 0.93931011,\n",
    " 'v_pnl': 0.88324705,\n",
    " 'xb': 1.667787,\n",
    " 'z': 0.1177627}\n",
    "\n",
    "x3={'a': 0.44534253,\n",
    " 'ssv':  -.9073797,\n",
    " 'tr_bsl':   0.29969275,\n",
    " 'tr_pnl':   0.31056620,\n",
    " 'v': 0.965766,\n",
    " 'xb': 1.52569355,\n",
    " 'z': 0.1591336}\n",
    "\n",
    "x4={'a': 0.44534253,\n",
    " 'ssv':  -1.564015,\n",
    " 'tr_bsl': 0.19521031,\n",
    " 'tr_pnl': 0.19703793,\n",
    " 'v_bsl': 1.80694264,\n",
    " 'v_pnl': 1.75763984,\n",
    " 'xb': 1.206618,\n",
    " 'z': 0.001013259}\n",
    "\n",
    "x4['tr'] = np.mean([x4['tr_bsl'], x4['tr_pnl']])\n",
    "x4['v'] = np.mean([x4['v_bsl'], x4['v_pnl']])\n",
    "x2['v'] = np.mean([x2['v_bsl'], x2['v_pnl']])\n",
    "x3['tr'] = np.mean([x3['tr_bsl'], x3['tr_pnl']])\n",
    "x1['a'] = np.mean([x1['a_bsl'], x1['a_pnl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finfo_list, yhat_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 26\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000052\n",
      "         Iterations: 87\n",
      "         Function evaluations: 240\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 36\n",
      "         Function evaluations: 84\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 22\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 21\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000057\n",
      "         Iterations: 23\n",
      "         Function evaluations: 65\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000051\n",
      "         Iterations: 141\n",
      "         Function evaluations: 370\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 59\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 71\n",
      "         Function evaluations: 173\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 24\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 28\n",
      "         Function evaluations: 71\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000013\n",
      "         Iterations: 21\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000073\n",
      "         Iterations: 99\n",
      "         Function evaluations: 268\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000167\n",
      "         Iterations: 70\n",
      "         Function evaluations: 183\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000048\n",
      "         Iterations: 79\n",
      "         Function evaluations: 212\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 25\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 55\n",
      "         Function evaluations: 134\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 25\n",
      "         Function evaluations: 64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000170\n",
      "         Iterations: 39\n",
      "         Function evaluations: 105\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 20\n",
      "         Function evaluations: 56\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000063\n",
      "         Iterations: 29\n",
      "         Function evaluations: 72\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 21\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000060\n",
      "         Iterations: 28\n",
      "         Function evaluations: 74\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 27\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 24\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000173\n",
      "         Iterations: 82\n",
      "         Function evaluations: 216\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 29\n",
      "         Function evaluations: 68\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 23\n",
      "         Function evaluations: 62\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 42\n",
      "         Function evaluations: 114\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000050\n",
      "         Iterations: 79\n",
      "         Function evaluations: 213\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000061\n",
      "         Iterations: 31\n",
      "         Function evaluations: 82\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 23\n",
      "         Function evaluations: 53\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000172\n",
      "         Iterations: 41\n",
      "         Function evaluations: 95\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "      \n",
    "      xinits_list = [deepcopy(xdct) for xdct in [x1,x2,x3,x4]]\n",
    "      parameter = 'v'\n",
    "      depends_on = {parameter:'Cond'}\n",
    "\n",
    "      d = '/'.join(['FinalRe', parameter+'iii'])\n",
    "      if not os.path.isdir(pth+d):\n",
    "            os.mkdir(pth+d)\n",
    "      os.chdir(pth+d)\n",
    "\n",
    "      for xi in xinits_list:\n",
    "            model = build.Model(data=redata, kind='xradd', inits=xi, depends_on=depends_on)\n",
    "            model.make_optimizer(tol=1.e-5, multiopt=True, maxfev=500)\n",
    "            opt=model.opt\n",
    "            opt.make_simulator()\n",
    "\n",
    "            ydata, ywts = model.avg_y, model.avg_wts\n",
    "            # STAGE 3 (Final Simplex)\n",
    "            yhat, finfo, xiv = opt.gradient_descent(y=ydata, wts=ywts, inits=xi, is_flat=False)\n",
    "\n",
    "            finfo_list.append(finfo)\n",
    "            yhat_list.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame([fi.T for fi in finfo_list])\n",
    "dff = dfx[['cnvrg', 'logp', 'chi', 'rchi', 'AIC', 'BIC', 'a', 'v_bsl', 'v_pnl', 'ssv', 'xb', 'tr', 'z']]\n",
    "dff.to_csv('xradd_v_bootinfo.csv', index=False)\n",
    "\n",
    "yfits = np.vstack([np.vstack(yh.reshape(2,16)) for yh in yhat_list])\n",
    "cond = ['bsl', 'pnl']*int(len(yfits)/2)\n",
    "yhatdf = pd.DataFrame(yfits)\n",
    "yhatdf.insert(0, 'Cond', cond)\n",
    "yhatdf.to_csv('xradd_v_bootfits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(12, 7))\n",
    "sns.set_context('notebook', font_scale=1.6)\n",
    "fits=m.fits.reshape(2,16)\n",
    "y=m.avg_y\n",
    "labels=['Baseline', 'Caution']\n",
    "datas=[redata.query('Cond==\"bsl\"'), redata.query('Cond==\"pnl\"')]\n",
    "colors=[\"#e74c3c\"]*2\n",
    "for i in range(m.ncond):\n",
    "      vis.plot_fits(y[i], fits[i], kind='radd', colors=[\"#e74c3c\"]*2, data=datas[i], axes=axes[i])\n",
    "\n",
    "for ax in axes.flatten():\n",
    "      if ax.is_last_col():\n",
    "            continue\n",
    "      ax.set_ylim(0,11)\n",
    "\n",
    "plt.savefig('re_drift_fitsII.png', dpi=500)\n",
    "plt.savefig('re_drift_fitsII.svg', rasterized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reactive triii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radd import build, vis\n",
    "from radd.toolbox import analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('xradd_tr')\n",
    "os.chdir('xradd_tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xi1={'a': array([ 0.67453]), 'z': 0.0010132587773621401, 'v': array([ 1.21102]), 'xb': array([ 1.20662]), 'ssv': -1.5640145715127098, 'tr': array([ 0.09438])}\n",
    "xi2={'a': array([ 0.3964]), 'z': 0.11776271765753309, 'v': array([ 0.90978]), 'xb': array([ 1.66779]), 'ssv': -0.78812139050158159, 'tr': array([ 0.29153])}\n",
    "xi3={'a': array([ 0.54262]), 'z': 0.043672738124915685, 'v': array([ 1.20861]), 'xb': array([ 0.8175]), 'ssv': -1.1048747883708683, 'tr': array([ 0.18567])}\n",
    "xi4={'a': array([ 0.44534]), 'z': 0.15913361713683202, 'v': array([ 0.96577]), 'xb': array([ 1.52569]), 'ssv': -0.90737967491616311, 'tr': array([ 0.30453])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inits = {'a': 0.44470913,\n",
    " 'ssv': -0.9415135,\n",
    " 'tr': 0.30481227,\n",
    " 'v': 1.07049551,\n",
    " 'xb': 1.5,\n",
    " 'z': 0.15049553}\n",
    "popt={'a': 0.54012, 'z': 0.042014925994818271, 'v': 1.20882, 'xb': .84012, 'ssv': -1.094068, 'tr': 0.18531}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['cnvrg', 'logp', 'chi', 'rchi', 'AIC', 'BIC', 'a', 'tr_bsl', 'tr_pnl', 'ssv', 'xb', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fidf=pd.DataFrame(columns=cols, index=np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basinhopping step 0: f 0.0021356\n",
      "basinhopping step 1: f 0.0021356 trial_f 0.142441 accepted 0  lowest_f 0.0021356\n",
      "basinhopping step 2: f 0.0021356 trial_f 0.553061 accepted 0  lowest_f 0.0021356\n",
      "basinhopping step 3: f 0.0641546 trial_f 0.0641546 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 4: f 0.0660867 trial_f 0.0660867 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 5: f 0.398568 trial_f 0.398568 accepted 1  lowest_f 0.0021356\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 6: f 0.883524 trial_f 0.883524 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 7: f 0.874997 trial_f 0.874997 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 8: f 1.19013 trial_f 1.19013 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 9: f 1.19013 trial_f 1.55139 accepted 0  lowest_f 0.0021356\n",
      "adaptive stepsize: acceptance rate 0.600000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 10: f 1.14489 trial_f 1.14489 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 11: f 1.50092 trial_f 1.50092 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 12: f 1.50092 trial_f 2.9314 accepted 0  lowest_f 0.0021356\n",
      "basinhopping step 13: f 1.60368 trial_f 1.60368 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 14: f 1.90339 trial_f 1.90339 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 15: f 2.9314 trial_f 2.9314 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 16: f 2.9314 trial_f 2.9314 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 17: f 1.60664 trial_f 1.60664 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 18: f 1.56036 trial_f 1.56036 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 19: f 1.46823 trial_f 1.46823 accepted 1  lowest_f 0.0021356\n",
      "adaptive stepsize: acceptance rate 0.750000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 1.60621 trial_f 1.60621 accepted 1  lowest_f 0.0021356\n",
      "basinhopping step 21: f 1.58721 trial_f 1.58721 accepted 1  lowest_f 0.0021356\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000003\n",
      "         Iterations: 59\n",
      "         Function evaluations: 161\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 0: f 2.78198\n",
      "basinhopping step 1: f 2.25325 trial_f 2.25325 accepted 1  lowest_f 2.25325\n",
      "found new global minimum on step 1 with function value 2.25325\n",
      "basinhopping step 2: f 2.25325 trial_f 3.40322 accepted 0  lowest_f 2.25325\n",
      "basinhopping step 3: f 2.47221 trial_f 2.47221 accepted 1  lowest_f 2.25325\n",
      "basinhopping step 4: f 2.3221 trial_f 2.3221 accepted 1  lowest_f 2.25325\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 1.882 trial_f 1.882 accepted 1  lowest_f 1.882\n",
      "found new global minimum on step 5 with function value 1.882\n",
      "basinhopping step 6: f 1.882 trial_f 2.34139 accepted 0  lowest_f 1.882\n",
      "basinhopping step 7: f 2.24171 trial_f 2.24171 accepted 1  lowest_f 1.882\n",
      "basinhopping step 8: f 1.57865 trial_f 1.57865 accepted 1  lowest_f 1.57865\n",
      "found new global minimum on step 8 with function value 1.57865\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 9: f 1.55563 trial_f 1.55563 accepted 1  lowest_f 1.55563\n",
      "found new global minimum on step 9 with function value 1.55563\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 1.95881 trial_f 1.95881 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 11: f 2.15633 trial_f 2.15633 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 12: f 2.18025 trial_f 2.18025 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 13: f 1.9271 trial_f 1.9271 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 14: f 1.9271 trial_f 2.06234 accepted 0  lowest_f 1.55563\n",
      "basinhopping step 15: f 2.1471 trial_f 2.1471 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 16: f 2.04584 trial_f 2.04584 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 17: f 2.01887 trial_f 2.01887 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 18: f 1.8631 trial_f 1.8631 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 19: f 2.11384 trial_f 2.11384 accepted 1  lowest_f 1.55563\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 2.13998 trial_f 2.13998 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 21: f 2.09344 trial_f 2.09344 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 22: f 2.06581 trial_f 2.06581 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 23: f 2.09574 trial_f 2.09574 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 24: f 2.10072 trial_f 2.10072 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 25: f 1.80324 trial_f 1.80324 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 26: f 2.11917 trial_f 2.11917 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 27: f 2.17742 trial_f 2.17742 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 28: f 2.16545 trial_f 2.16545 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 29: f 2.14106 trial_f 2.14106 accepted 1  lowest_f 1.55563\n",
      "adaptive stepsize: acceptance rate 0.866667 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 2.06112 trial_f 2.06112 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 31: f 1.78729 trial_f 1.78729 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 32: f 1.65523 trial_f 1.65523 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 33: f 1.68018 trial_f 1.68018 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 34: f 2.04928 trial_f 2.04928 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 35: f 2.04928 trial_f 3.34887 accepted 0  lowest_f 1.55563\n",
      "basinhopping step 36: f 2.21333 trial_f 2.21333 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 37: f 1.92337 trial_f 1.92337 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 38: f 1.72445 trial_f 1.72445 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 39: f 2.13191 trial_f 2.13191 accepted 1  lowest_f 1.55563\n",
      "adaptive stepsize: acceptance rate 0.875000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "basinhopping step 40: f 2.15524 trial_f 2.15524 accepted 1  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 41: f 2.16359 trial_f 2.16359 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 42: f 2.16359 trial_f 9.69491 accepted 0  lowest_f 1.55563\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 43: f 2.08947 trial_f 2.08947 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 44: f 1.60151 trial_f 1.60151 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 45: f 1.75013 trial_f 1.75013 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 46: f 2.05985 trial_f 2.05985 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 47: f 2.17555 trial_f 2.17555 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 48: f 1.77273 trial_f 1.77273 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 49: f 1.89895 trial_f 1.89895 accepted 1  lowest_f 1.55563\n",
      "adaptive stepsize: acceptance rate 0.880000 target 0.500000 new stepsize 0.0846754 old stepsize 0.0762079\n",
      "basinhopping step 50: f 1.56369 trial_f 1.56369 accepted 1  lowest_f 1.55563\n",
      "basinhopping step 0: f 14.379\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 1: f 14.379 trial_f 18.1405 accepted 0  lowest_f 14.379\n",
      "basinhopping step 2: f 14.379 trial_f 16.2551 accepted 0  lowest_f 14.379\n",
      "basinhopping step 3: f 14.379 trial_f 15.0308 accepted 0  lowest_f 14.379\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 4: f 16.5381 trial_f 16.5381 accepted 1  lowest_f 14.379\n",
      "basinhopping step 5: f 16.5381 trial_f 19.3671 accepted 0  lowest_f 14.379\n",
      "basinhopping step 6: f 14.809 trial_f 14.809 accepted 1  lowest_f 14.379\n",
      "basinhopping step 7: f 14.7448 trial_f 14.7448 accepted 1  lowest_f 14.379\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 8: f 14.7448 trial_f 19.8712 accepted 0  lowest_f 14.379\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 9: f 11.3149 trial_f 11.3149 accepted 1  lowest_f 11.3149\n",
      "found new global minimum on step 9 with function value 11.3149\n",
      "adaptive stepsize: acceptance rate 0.400000 target 0.500000 new stepsize 0.045 old stepsize 0.05\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 10: f 11.3149 trial_f 12.5352 accepted 0  lowest_f 11.3149\n",
      "basinhopping step 11: f 11.3149 trial_f 16.3306 accepted 0  lowest_f 11.3149\n",
      "basinhopping step 12: f 10.7967 trial_f 10.7967 accepted 1  lowest_f 10.7967\n",
      "found new global minimum on step 12 with function value 10.7967\n",
      "basinhopping step 13: f 9.63876 trial_f 9.63876 accepted 1  lowest_f 9.63876\n",
      "found new global minimum on step 13 with function value 9.63876\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 14: f 9.30204 trial_f 9.30204 accepted 1  lowest_f 9.30204\n",
      "found new global minimum on step 14 with function value 9.30204\n",
      "basinhopping step 15: f 9.08429 trial_f 9.08429 accepted 1  lowest_f 9.08429\n",
      "found new global minimum on step 15 with function value 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 16: f 10.525 trial_f 10.525 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 17: f 10.2288 trial_f 10.2288 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 18: f 10.6805 trial_f 10.6805 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 19: f 10.6805 trial_f 10.9347 accepted 0  lowest_f 9.08429\n",
      "adaptive stepsize: acceptance rate 0.550000 target 0.500000 new stepsize 0.05 old stepsize 0.045\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 20: f 10.6805 trial_f 11.749 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 21: f 11.8095 trial_f 11.8095 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 22: f 10.8478 trial_f 10.8478 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 23: f 10.1258 trial_f 10.1258 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 24: f 9.84651 trial_f 9.84651 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 25: f 9.58776 trial_f 9.58776 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 26: f 9.23166 trial_f 9.23166 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 27: f 9.66383 trial_f 9.66383 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 28: f 9.34684 trial_f 9.34684 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 29: f 9.4131 trial_f 9.4131 accepted 1  lowest_f 9.08429\n",
      "adaptive stepsize: acceptance rate 0.666667 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 30: f 9.4131 trial_f 10.9419 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 31: f 9.18493 trial_f 9.18493 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 32: f 10.9781 trial_f 10.9781 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 33: f 9.19089 trial_f 9.19089 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 34: f 10.5159 trial_f 10.5159 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 35: f 9.22951 trial_f 9.22951 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 36: f 9.22951 trial_f 10.2192 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 37: f 9.22951 trial_f 11.2297 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 38: f 9.59112 trial_f 9.59112 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 39: f 9.90451 trial_f 9.90451 accepted 1  lowest_f 9.08429\n",
      "adaptive stepsize: acceptance rate 0.675000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 40: f 10.4996 trial_f 10.4996 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 41: f 9.40359 trial_f 9.40359 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 42: f 9.40359 trial_f 11.3374 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 43: f 9.34559 trial_f 9.34559 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 44: f 9.68972 trial_f 9.68972 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 45: f 9.50402 trial_f 9.50402 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 46: f 9.61268 trial_f 9.61268 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 47: f 9.61268 trial_f 10.6743 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 48: f 9.61268 trial_f 10.9601 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 49: f 9.35172 trial_f 9.35172 accepted 1  lowest_f 9.08429\n",
      "adaptive stepsize: acceptance rate 0.680000 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 50: f 9.35172 trial_f 11.2922 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 51: f 9.35443 trial_f 9.35443 accepted 1  lowest_f 9.08429\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 52: f 9.35443 trial_f 9.57774 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 53: f 9.53286 trial_f 9.53286 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 54: f 9.33944 trial_f 9.33944 accepted 1  lowest_f 9.08429\n",
      "basinhopping step 55: f 9.33944 trial_f 11.3111 accepted 0  lowest_f 9.08429\n",
      "basinhopping step 56: f 9.37049 trial_f 9.37049 accepted 1  lowest_f 9.08429\n",
      "basinhopping finished\n",
      "Warning: Maximum number of iterations has been exceeded.\n",
      "basinhopping step 0: f 0.00204081\n",
      "basinhopping step 1: f 0.0422757 trial_f 0.0422757 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 2: f 0.0591433 trial_f 0.0591433 accepted 1  lowest_f 0.00204081\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 3: f 0.12412 trial_f 0.12412 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 4: f 0.677959 trial_f 0.677959 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 5: f 0.341292 trial_f 0.341292 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 6: f 0.137713 trial_f 0.137713 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 7: f 0.0163161 trial_f 0.0163161 accepted 1  lowest_f 0.00204081\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 8: f 0.0163161 trial_f 0.868319 accepted 0  lowest_f 0.00204081\n",
      "basinhopping step 9: f 0.0875804 trial_f 0.0875804 accepted 1  lowest_f 0.00204081\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 0.778242 trial_f 0.778242 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 11: f 0.228766 trial_f 0.228766 accepted 1  lowest_f 0.00204081\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 12: f 0.262006 trial_f 0.262006 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 13: f 0.262006 trial_f 0.556098 accepted 0  lowest_f 0.00204081\n",
      "basinhopping step 14: f 0.0624809 trial_f 0.0624809 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 15: f 0.710168 trial_f 0.710168 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 16: f 0.710168 trial_f 1.13357 accepted 0  lowest_f 0.00204081\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 17: f 0.710168 trial_f 3.09722 accepted 0  lowest_f 0.00204081\n",
      "basinhopping step 18: f 0.710168 trial_f 2.94484 accepted 0  lowest_f 0.00204081\n",
      "basinhopping step 19: f 0.683733 trial_f 0.683733 accepted 1  lowest_f 0.00204081\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 0.0708742 trial_f 0.0708742 accepted 1  lowest_f 0.00204081\n",
      "basinhopping step 21: f 0.0708742 trial_f 0.30475 accepted 0  lowest_f 0.00204081\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000003\n",
      "         Iterations: 49\n",
      "         Function evaluations: 138\n",
      "basinhopping step 0: f 2.83518\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 1: f 3.5913 trial_f 3.5913 accepted 1  lowest_f 2.83518\n",
      "basinhopping step 2: f 3.45364 trial_f 3.45364 accepted 1  lowest_f 2.83518\n",
      "basinhopping step 3: f 3.29961 trial_f 3.29961 accepted 1  lowest_f 2.83518\n",
      "basinhopping step 4: f 3.18528 trial_f 3.18528 accepted 1  lowest_f 2.83518\n",
      "basinhopping step 5: f 3.18528 trial_f 3.43516 accepted 0  lowest_f 2.83518\n",
      "basinhopping step 6: f 2.68046 trial_f 2.68046 accepted 1  lowest_f 2.68046\n",
      "found new global minimum on step 6 with function value 2.68046\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 7: f 3.63559 trial_f 3.63559 accepted 1  lowest_f 2.68046\n",
      "basinhopping step 8: f 2.68821 trial_f 2.68821 accepted 1  lowest_f 2.68046\n",
      "basinhopping step 9: f 2.68821 trial_f 4.02302 accepted 0  lowest_f 2.68046\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 1.99422 trial_f 1.99422 accepted 1  lowest_f 1.99422\n",
      "found new global minimum on step 10 with function value 1.99422\n",
      "basinhopping step 11: f 1.60786 trial_f 1.60786 accepted 1  lowest_f 1.60786\n",
      "found new global minimum on step 11 with function value 1.60786\n",
      "basinhopping step 12: f 1.7957 trial_f 1.7957 accepted 1  lowest_f 1.60786\n",
      "basinhopping step 13: f 2.6552 trial_f 2.6552 accepted 1  lowest_f 1.60786\n",
      "basinhopping step 14: f 2.6552 trial_f 3.53721 accepted 0  lowest_f 1.60786\n",
      "basinhopping step 15: f 2.0978 trial_f 2.0978 accepted 1  lowest_f 1.60786\n",
      "basinhopping step 16: f 3.39971 trial_f 3.39971 accepted 1  lowest_f 1.60786\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 17: f 3.39971 trial_f 4.45294 accepted 0  lowest_f 1.60786\n",
      "basinhopping step 18: f 4.33126 trial_f 4.33126 accepted 1  lowest_f 1.60786\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 19: f 4.18143 trial_f 4.18143 accepted 1  lowest_f 1.60786\n",
      "adaptive stepsize: acceptance rate 0.750000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 3.51231 trial_f 3.51231 accepted 1  lowest_f 1.60786\n",
      "basinhopping step 21: f 3.51231 trial_f 4.20963 accepted 0  lowest_f 1.60786\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 22: f 4.39512 trial_f 4.39512 accepted 1  lowest_f 1.60786\n",
      "basinhopping step 23: f 3.41945 trial_f 3.41945 accepted 1  lowest_f 1.60786\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 24: f 1.88416 trial_f 1.88416 accepted 1  lowest_f 1.60786\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 25: f 1.58123 trial_f 1.58123 accepted 1  lowest_f 1.58123\n",
      "found new global minimum on step 25 with function value 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 26: f 1.58123 trial_f 1.85343 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 27: f 2.02272 trial_f 2.02272 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 28: f 2.16755 trial_f 2.16755 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 29: f 2.14908 trial_f 2.14908 accepted 1  lowest_f 1.58123\n",
      "adaptive stepsize: acceptance rate 0.766667 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 2.14908 trial_f 5.92872 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 31: f 2.17283 trial_f 2.17283 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 32: f 2.17283 trial_f 5.91396 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 33: f 2.17283 trial_f 5.97576 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 34: f 2.17283 trial_f 9.69491 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 35: f 2.16497 trial_f 2.16497 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 36: f 2.07717 trial_f 2.07717 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 37: f 1.9187 trial_f 1.9187 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 38: f 1.95459 trial_f 1.95459 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 39: f 1.69087 trial_f 1.69087 accepted 1  lowest_f 1.58123\n",
      "adaptive stepsize: acceptance rate 0.725000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "basinhopping step 40: f 1.69087 trial_f 1.95318 accepted 0  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 41: f 1.60362 trial_f 1.60362 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 42: f 2.08106 trial_f 2.08106 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 43: f 2.13453 trial_f 2.13453 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 44: f 2.04965 trial_f 2.04965 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 45: f 2.16317 trial_f 2.16317 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 46: f 2.1449 trial_f 2.1449 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 47: f 2.15589 trial_f 2.15589 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 48: f 2.15589 trial_f 5.92121 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 49: f 1.98615 trial_f 1.98615 accepted 1  lowest_f 1.58123\n",
      "adaptive stepsize: acceptance rate 0.740000 target 0.500000 new stepsize 0.0846754 old stepsize 0.0762079\n",
      "basinhopping step 50: f 1.91669 trial_f 1.91669 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 51: f 2.20692 trial_f 2.20692 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 52: f 2.18298 trial_f 2.18298 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 53: f 2.05766 trial_f 2.05766 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 54: f 2.18552 trial_f 2.18552 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 55: f 2.21082 trial_f 2.21082 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 56: f 2.05876 trial_f 2.05876 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 57: f 2.05876 trial_f 9.69491 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 58: f 2.07341 trial_f 2.07341 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 59: f 2.13724 trial_f 2.13724 accepted 1  lowest_f 1.58123\n",
      "adaptive stepsize: acceptance rate 0.766667 target 0.500000 new stepsize 0.0940838 old stepsize 0.0846754\n",
      "basinhopping step 60: f 1.91853 trial_f 1.91853 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 61: f 2.02309 trial_f 2.02309 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 62: f 2.02309 trial_f 2.14542 accepted 0  lowest_f 1.58123\n",
      "basinhopping step 63: f 1.94709 trial_f 1.94709 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 64: f 2.20979 trial_f 2.20979 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 65: f 2.16678 trial_f 2.16678 accepted 1  lowest_f 1.58123\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 66: f 1.88508 trial_f 1.88508 accepted 1  lowest_f 1.58123\n",
      "basinhopping step 0: f 14.5063\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 1: f 14.9867 trial_f 14.9867 accepted 1  lowest_f 14.5063\n",
      "basinhopping step 2: f 11.4925 trial_f 11.4925 accepted 1  lowest_f 11.4925\n",
      "found new global minimum on step 2 with function value 11.4925\n",
      "basinhopping step 3: f 11.4925 trial_f 16.5407 accepted 0  lowest_f 11.4925\n",
      "basinhopping step 4: f 11.4925 trial_f 16.803 accepted 0  lowest_f 11.4925\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 13.3231 trial_f 13.3231 accepted 1  lowest_f 11.4925\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e88d0ee0ce57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'full'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m       \u001b[1;31m#finfo_list.append(m.fitinfo.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[1;31m#x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/build.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, save, savepth, ntrials, tol, maxfev, niter, disp, prob, multiopt, stage, inits, y)\u001b[0m\n\u001b[0;32m     74\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                   \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m(self, save, savepth)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'average'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__opt_routine__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'subjects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bootstrap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__indx_optimize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36m__opt_routine__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mflat_yh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_fi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# STAGE 2 (Nudge/BasinHopping) & STAGE 3 (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_conditional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_conditional\u001b[1;34m(self, p, y, precond)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprecond\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiopt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                   \u001b[1;31m# pretune conditional parameters (1/time)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                   \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_basin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;31m# STAGE 3: (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36msingle_basin\u001b[1;34m(self, p, disp, interval, niter, stepsize, nsuccess)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__update__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_flat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                   \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasinhopping_minimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimizer_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter_success\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                   \u001b[0mxbasin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mbasinhopping\u001b[1;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success)\u001b[0m\n\u001b[0;32m    612\u001b[0m                \" successfully\"]\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mone_cycle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mxtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menergy_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monte_carlo_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m_monte_carlo_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# do a local minimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mminres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_after_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mx_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0menergy_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x0)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[1;32m--> 447\u001b[1;33m                              **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cobyla'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36m_minimize_tnc\u001b[1;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    407\u001b[0m                                         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxCGit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                         \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepmx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                                         xtol, pgtol, rescale, callback)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mfunv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjacv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapprox_fprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36mapprox_fprime\u001b[1;34m(xk, f, epsilon, *args)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \"\"\"\n\u001b[1;32m--> 618\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/optimize.pyc\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    550\u001b[0m     \"\"\"\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf0\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mf0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[0mei\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36mbasinhopping_minimizer\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.e5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim_fx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__iter__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36msimulate_radd\u001b[1;34m(self, p, analyze)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mnssd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnssd\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mnss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnss\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mnc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncond\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mntot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mDVg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxtb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mPg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'radd'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                   \u001b[0mDVg\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m=build.Model(data=redata, kind='xradd', depends_on={'tr':'Cond'}, inits=inits)\n",
    "m.inits=popt\n",
    "for i in range(20):\n",
    "      \n",
    "      m.optimize(stage='full', multiopt=True)      \n",
    "      #finfo_list.append(m.fitinfo.T) \n",
    "      #x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\n",
    "      for c in cols:\n",
    "            fidf.loc[i, c]=m.fitinfo[c]\n",
    "      fidf.to_csv(\"finfo_xradd_tr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = {'a_bsl':   0.529353,\n",
    "'a_pnl': 0.553150,\n",
    "'xb': 0.817502,\n",
    "'ssv': -1.104875,\n",
    "'tr': 0.185667,\n",
    "'v': 1.208608,\n",
    "'z': 0.0436727}\n",
    "\n",
    "x2 = {'a': 0.3964024,\n",
    " 'ssv': -0.7881214,\n",
    " 'tr': 0.2915253,\n",
    " 'v_bsl': 0.93931011,\n",
    " 'v_pnl': 0.88324705,\n",
    " 'xb': 1.667787,\n",
    " 'z': 0.1177627}\n",
    "\n",
    "x3={'a': 0.44534253,\n",
    " 'ssv':  -.9073797,\n",
    " 'tr_bsl':   0.29969275,\n",
    " 'tr_pnl':   0.31056620,\n",
    " 'v': 0.965766,\n",
    " 'xb': 1.52569355,\n",
    " 'z': 0.1591336}\n",
    "\n",
    "x4={'a': 0.44534253,\n",
    " 'ssv':  -1.564015,\n",
    " 'tr_bsl': 0.19521031,\n",
    " 'tr_pnl': 0.19703793,\n",
    " 'v_bsl': 1.80694264,\n",
    " 'v_pnl': 1.75763984,\n",
    " 'xb': 1.206618,\n",
    " 'z': 0.001013259}\n",
    "\n",
    "x4['tr'] = np.mean([x4['tr_bsl'], x4['tr_pnl']])\n",
    "x4['v'] = np.mean([x4['v_bsl'], x4['v_pnl']])\n",
    "x2['v'] = np.mean([x2['v_bsl'], x2['v_pnl']])\n",
    "x3['tr'] = np.mean([x3['tr_bsl'], x3['tr_pnl']])\n",
    "x1['a'] = np.mean([x1['a_bsl'], x1['a_pnl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finfo_list, yhat_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 26\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000052\n",
      "         Iterations: 87\n",
      "         Function evaluations: 240\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 36\n",
      "         Function evaluations: 84\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 22\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 21\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000057\n",
      "         Iterations: 23\n",
      "         Function evaluations: 65\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000051\n",
      "         Iterations: 141\n",
      "         Function evaluations: 370\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 59\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 71\n",
      "         Function evaluations: 173\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 24\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 28\n",
      "         Function evaluations: 71\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000013\n",
      "         Iterations: 21\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000073\n",
      "         Iterations: 99\n",
      "         Function evaluations: 268\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000167\n",
      "         Iterations: 70\n",
      "         Function evaluations: 183\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000048\n",
      "         Iterations: 79\n",
      "         Function evaluations: 212\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 25\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 55\n",
      "         Function evaluations: 134\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 25\n",
      "         Function evaluations: 64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000170\n",
      "         Iterations: 39\n",
      "         Function evaluations: 105\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 20\n",
      "         Function evaluations: 56\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000063\n",
      "         Iterations: 29\n",
      "         Function evaluations: 72\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 21\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000060\n",
      "         Iterations: 28\n",
      "         Function evaluations: 74\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 27\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 24\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000173\n",
      "         Iterations: 82\n",
      "         Function evaluations: 216\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 29\n",
      "         Function evaluations: 68\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 23\n",
      "         Function evaluations: 62\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 42\n",
      "         Function evaluations: 114\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000050\n",
      "         Iterations: 79\n",
      "         Function evaluations: 213\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000061\n",
      "         Iterations: 31\n",
      "         Function evaluations: 82\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 23\n",
      "         Function evaluations: 53\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000172\n",
      "         Iterations: 41\n",
      "         Function evaluations: 95\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "      \n",
    "      xinits_list = [deepcopy(xdct) for xdct in [x1,x2,x3,x4]]\n",
    "      parameter = 'v'\n",
    "      depends_on = {parameter:'Cond'}\n",
    "\n",
    "      d = '/'.join(['FinalRe', parameter+'iii'])\n",
    "      if not os.path.isdir(pth+d):\n",
    "            os.mkdir(pth+d)\n",
    "      os.chdir(pth+d)\n",
    "\n",
    "      for xi in xinits_list:\n",
    "            model = build.Model(data=redata, kind='xradd', inits=xi, depends_on=depends_on)\n",
    "            model.make_optimizer(tol=1.e-5, multiopt=True, maxfev=500)\n",
    "            opt=model.opt\n",
    "            opt.make_simulator()\n",
    "\n",
    "            ydata, ywts = model.avg_y, model.avg_wts\n",
    "            # STAGE 3 (Final Simplex)\n",
    "            yhat, finfo, xiv = opt.gradient_descent(y=ydata, wts=ywts, inits=xi, is_flat=False)\n",
    "\n",
    "            finfo_list.append(finfo)\n",
    "            yhat_list.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame([fi.T for fi in finfo_list])\n",
    "dff = dfx[['cnvrg', 'logp', 'chi', 'rchi', 'AIC', 'BIC', 'a', 'v_bsl', 'v_pnl', 'ssv', 'xb', 'tr', 'z']]\n",
    "dff.to_csv('xradd_v_bootinfo.csv', index=False)\n",
    "\n",
    "yfits = np.vstack([np.vstack(yh.reshape(2,16)) for yh in yhat_list])\n",
    "cond = ['bsl', 'pnl']*int(len(yfits)/2)\n",
    "yhatdf = pd.DataFrame(yfits)\n",
    "yhatdf.insert(0, 'Cond', cond)\n",
    "yhatdf.to_csv('xradd_v_bootfits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(12, 7))\n",
    "sns.set_context('notebook', font_scale=1.6)\n",
    "fits=m.fits.reshape(2,16)\n",
    "y=m.avg_y\n",
    "labels=['Baseline', 'Caution']\n",
    "datas=[redata.query('Cond==\"bsl\"'), redata.query('Cond==\"pnl\"')]\n",
    "colors=[\"#e74c3c\"]*2\n",
    "for i in range(m.ncond):\n",
    "      vis.plot_fits(y[i], fits[i], kind='radd', colors=[\"#e74c3c\"]*2, data=datas[i], axes=axes[i])\n",
    "\n",
    "for ax in axes.flatten():\n",
    "      if ax.is_last_col():\n",
    "            continue\n",
    "      ax.set_ylim(0,11)\n",
    "\n",
    "plt.savefig('re_drift_fitsII.png', dpi=500)\n",
    "plt.savefig('re_drift_fitsII.svg', rasterized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

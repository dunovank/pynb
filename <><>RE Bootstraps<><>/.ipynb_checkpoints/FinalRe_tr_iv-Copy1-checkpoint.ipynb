{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reactive A IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radd import build, vis\n",
    "from radd.toolbox import analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('xradd_a')\n",
    "os.chdir('xradd_a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xi1={'a': array([ 0.67453]), 'z': 0.0010132587773621401, 'v': array([ 1.21102]), 'xb': array([ 1.20662]), 'ssv': -1.5640145715127098, 'tr': array([ 0.09438])}\n",
    "xi2={'a': array([ 0.3964]), 'z': 0.11776271765753309, 'v': array([ 0.90978]), 'xb': array([ 1.66779]), 'ssv': -0.78812139050158159, 'tr': array([ 0.29153])}\n",
    "xi3={'a': array([ 0.54262]), 'z': 0.043672738124915685, 'v': array([ 1.20861]), 'xb': array([ 0.8175]), 'ssv': -1.1048747883708683, 'tr': array([ 0.18567])}\n",
    "xi4={'a': array([ 0.44534]), 'z': 0.15913361713683202, 'v': array([ 0.96577]), 'xb': array([ 1.52569]), 'ssv': -0.90737967491616311, 'tr': array([ 0.30453])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['cnvrg', 'logp', 'chi', 'rchi', 'AIC', 'BIC', 'a_bsl', 'a_pnl', 'ssv', 'xb', 'tr', 'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fidf=pd.DataFrame(columns=cols, index=np.arange(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inits = {'a': 0.44470913,\n",
    " 'ssv': -0.9415135,\n",
    " 'tr': 0.30481227,\n",
    " 'v': 1.07049551,\n",
    " 'xb': 1.5,\n",
    " 'z': 0.15049553}\n",
    "popt={'a': 0.54012, 'z': 0.042014925994818271, 'v': 1.20882, 'xb': .84012, 'ssv': -1.094068, 'tr': 0.18531}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 0: f 0.0017189\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 1: f 0.00379515 trial_f 0.00379515 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 2: f 0.0023184 trial_f 0.0023184 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 3: f 0.00234736 trial_f 0.00234736 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 4: f 0.0232394 trial_f 0.0232394 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 5: f 0.162286 trial_f 0.162286 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 6: f 0.137265 trial_f 0.137265 accepted 1  lowest_f 0.0017189\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 7: f 0.0360394 trial_f 0.0360394 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 8: f 0.0135372 trial_f 0.0135372 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 9: f 0.17403 trial_f 0.17403 accepted 1  lowest_f 0.0017189\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 0.153657 trial_f 0.153657 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 11: f 0.153657 trial_f 0.955829 accepted 0  lowest_f 0.0017189\n",
      "basinhopping step 12: f 0.153657 trial_f 0.399071 accepted 0  lowest_f 0.0017189\n",
      "basinhopping step 13: f 0.0838302 trial_f 0.0838302 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 14: f 0.0632239 trial_f 0.0632239 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 15: f 0.300457 trial_f 0.300457 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 16: f 0.300457 trial_f 3.63378 accepted 0  lowest_f 0.0017189\n",
      "basinhopping step 17: f 0.0989995 trial_f 0.0989995 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 18: f 0.0989995 trial_f 0.557484 accepted 0  lowest_f 0.0017189\n",
      "basinhopping step 19: f 0.199292 trial_f 0.199292 accepted 1  lowest_f 0.0017189\n",
      "adaptive stepsize: acceptance rate 0.750000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 0.340441 trial_f 0.340441 accepted 1  lowest_f 0.0017189\n",
      "basinhopping step 21: f 0.303763 trial_f 0.303763 accepted 1  lowest_f 0.0017189\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000002\n",
      "         Iterations: 54\n",
      "         Function evaluations: 149\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 0: f 2.85692\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 1: f 2.26176 trial_f 2.26176 accepted 1  lowest_f 2.26176\n",
      "found new global minimum on step 1 with function value 2.26176\n",
      "basinhopping step 2: f 1.87925 trial_f 1.87925 accepted 1  lowest_f 1.87925\n",
      "found new global minimum on step 2 with function value 1.87925\n",
      "basinhopping step 3: f 1.98387 trial_f 1.98387 accepted 1  lowest_f 1.87925\n",
      "basinhopping step 4: f 2.25433 trial_f 2.25433 accepted 1  lowest_f 1.87925\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 1.98791 trial_f 1.98791 accepted 1  lowest_f 1.87925\n",
      "basinhopping step 6: f 1.98791 trial_f 2.21486 accepted 0  lowest_f 1.87925\n",
      "basinhopping step 7: f 1.92758 trial_f 1.92758 accepted 1  lowest_f 1.87925\n",
      "basinhopping step 8: f 1.92758 trial_f 2.43526 accepted 0  lowest_f 1.87925\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 9: f 2.26589 trial_f 2.26589 accepted 1  lowest_f 1.87925\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 2.02767 trial_f 2.02767 accepted 1  lowest_f 1.87925\n",
      "basinhopping step 11: f 1.8332 trial_f 1.8332 accepted 1  lowest_f 1.8332\n",
      "found new global minimum on step 11 with function value 1.8332\n",
      "basinhopping step 12: f 1.99706 trial_f 1.99706 accepted 1  lowest_f 1.8332\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 13: f 1.75999 trial_f 1.75999 accepted 1  lowest_f 1.75999\n",
      "found new global minimum on step 13 with function value 1.75999\n",
      "basinhopping step 14: f 1.77883 trial_f 1.77883 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 15: f 1.76958 trial_f 1.76958 accepted 1  lowest_f 1.75999\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 16: f 1.76704 trial_f 1.76704 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 17: f 2.11747 trial_f 2.11747 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 18: f 2.05421 trial_f 2.05421 accepted 1  lowest_f 1.75999\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 19: f 2.48666 trial_f 2.48666 accepted 1  lowest_f 1.75999\n",
      "adaptive stepsize: acceptance rate 0.850000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 2.48666 trial_f 3.0925 accepted 0  lowest_f 1.75999\n",
      "basinhopping step 21: f 2.84243 trial_f 2.84243 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 22: f 2.61358 trial_f 2.61358 accepted 1  lowest_f 1.75999\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 23: f 1.99329 trial_f 1.99329 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 24: f 2.21195 trial_f 2.21195 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 25: f 2.12673 trial_f 2.12673 accepted 1  lowest_f 1.75999\n",
      "basinhopping step 26: f 1.84392 trial_f 1.84392 accepted 1  lowest_f 1.75999\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 27: f 1.75464 trial_f 1.75464 accepted 1  lowest_f 1.75464\n",
      "found new global minimum on step 27 with function value 1.75464\n",
      "basinhopping step 28: f 1.76373 trial_f 1.76373 accepted 1  lowest_f 1.75464\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 29: f 1.76681 trial_f 1.76681 accepted 1  lowest_f 1.75464\n",
      "adaptive stepsize: acceptance rate 0.866667 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 30: f 1.93535 trial_f 1.93535 accepted 1  lowest_f 1.75464\n",
      "basinhopping step 31: f 1.87821 trial_f 1.87821 accepted 1  lowest_f 1.75464\n",
      "basinhopping step 32: f 1.97049 trial_f 1.97049 accepted 1  lowest_f 1.75464\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 33: f 1.95857 trial_f 1.95857 accepted 1  lowest_f 1.75464\n",
      "basinhopping step 34: f 1.95857 trial_f 2.15228 accepted 0  lowest_f 1.75464\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 35: f 2.00806 trial_f 2.00806 accepted 1  lowest_f 1.75464\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 36: f 1.78279 trial_f 1.78279 accepted 1  lowest_f 1.75464\n",
      "basinhopping step 37: f 1.8338 trial_f 1.8338 accepted 1  lowest_f 1.75464\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 38: f 1.78315 trial_f 1.78315 accepted 1  lowest_f 1.75464\n",
      "basinhopping step 39: f 1.75177 trial_f 1.75177 accepted 1  lowest_f 1.75177\n",
      "found new global minimum on step 39 with function value 1.75177\n",
      "adaptive stepsize: acceptance rate 0.875000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "basinhopping step 40: f 2.07596 trial_f 2.07596 accepted 1  lowest_f 1.75177\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 41: f 1.75719 trial_f 1.75719 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 42: f 1.75719 trial_f 1.96771 accepted 0  lowest_f 1.75177\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 43: f 1.90689 trial_f 1.90689 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 44: f 1.84829 trial_f 1.84829 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 45: f 2.03118 trial_f 2.03118 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 46: f 1.9428 trial_f 1.9428 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 47: f 1.82123 trial_f 1.82123 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 48: f 2.09887 trial_f 2.09887 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 49: f 1.99586 trial_f 1.99586 accepted 1  lowest_f 1.75177\n",
      "adaptive stepsize: acceptance rate 0.880000 target 0.500000 new stepsize 0.0846754 old stepsize 0.0762079\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 50: f 2.06232 trial_f 2.06232 accepted 1  lowest_f 1.75177\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 51: f 2.11971 trial_f 2.11971 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 52: f 1.96607 trial_f 1.96607 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 53: f 2.18234 trial_f 2.18234 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 54: f 1.97813 trial_f 1.97813 accepted 1  lowest_f 1.75177\n",
      "basinhopping step 55: f 2.08887 trial_f 2.08887 accepted 1  lowest_f 1.75177\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 56: f 1.74583 trial_f 1.74583 accepted 1  lowest_f 1.74583\n",
      "found new global minimum on step 56 with function value 1.74583\n",
      "basinhopping step 57: f 1.78873 trial_f 1.78873 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 58: f 1.77294 trial_f 1.77294 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 59: f 1.92632 trial_f 1.92632 accepted 1  lowest_f 1.74583\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0940838 old stepsize 0.0846754\n",
      "basinhopping step 60: f 1.84972 trial_f 1.84972 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 61: f 2.00809 trial_f 2.00809 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 62: f 2.00809 trial_f 3.08373 accepted 0  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 63: f 1.78054 trial_f 1.78054 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 64: f 1.8752 trial_f 1.8752 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 65: f 2.02803 trial_f 2.02803 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 66: f 2.05493 trial_f 2.05493 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 67: f 2.16256 trial_f 2.16256 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 68: f 2.21703 trial_f 2.21703 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 69: f 2.13201 trial_f 2.13201 accepted 1  lowest_f 1.74583\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.104538 old stepsize 0.0940838\n",
      "basinhopping step 70: f 1.78697 trial_f 1.78697 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 71: f 1.78697 trial_f 1.84005 accepted 0  lowest_f 1.74583\n",
      "basinhopping step 72: f 1.78697 trial_f 2.1468 accepted 0  lowest_f 1.74583\n",
      "basinhopping step 73: f 1.96385 trial_f 1.96385 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 74: f 1.87524 trial_f 1.87524 accepted 1  lowest_f 1.74583\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 75: f 1.87524 trial_f 2.19139 accepted 0  lowest_f 1.74583\n",
      "basinhopping step 76: f 1.99602 trial_f 1.99602 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 77: f 1.76224 trial_f 1.76224 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 78: f 2.13524 trial_f 2.13524 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 79: f 2.20979 trial_f 2.20979 accepted 1  lowest_f 1.74583\n",
      "adaptive stepsize: acceptance rate 0.875000 target 0.500000 new stepsize 0.116153 old stepsize 0.104538\n",
      "basinhopping step 80: f 2.19427 trial_f 2.19427 accepted 1  lowest_f 1.74583\n",
      "basinhopping step 0: f 14.352\n",
      "basinhopping step 1: f 12.532 trial_f 12.532 accepted 1  lowest_f 12.532\n",
      "found new global minimum on step 1 with function value 12.532\n",
      "basinhopping step 2: f 10.7246 trial_f 10.7246 accepted 1  lowest_f 10.7246\n",
      "found new global minimum on step 2 with function value 10.7246\n",
      "basinhopping step 3: f 11.2434 trial_f 11.2434 accepted 1  lowest_f 10.7246\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 4: f 10.1487 trial_f 10.1487 accepted 1  lowest_f 10.1487\n",
      "found new global minimum on step 4 with function value 10.1487\n",
      "basinhopping step 5: f 10.0693 trial_f 10.0693 accepted 1  lowest_f 10.0693\n",
      "found new global minimum on step 5 with function value 10.0693\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 6: f 10.0923 trial_f 10.0923 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 7: f 10.0923 trial_f 10.7358 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 8: f 10.2996 trial_f 10.2996 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 9: f 10.1523 trial_f 10.1523 accepted 1  lowest_f 10.0693\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 10.1523 trial_f 11.2999 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 11: f 10.3417 trial_f 10.3417 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 12: f 10.3856 trial_f 10.3856 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 13: f 10.3856 trial_f 11.1789 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 14: f 10.1328 trial_f 10.1328 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 15: f 10.3885 trial_f 10.3885 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 16: f 10.451 trial_f 10.451 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 17: f 10.266 trial_f 10.266 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 18: f 11.1373 trial_f 11.1373 accepted 1  lowest_f 10.0693\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 19: f 11.8195 trial_f 11.8195 accepted 1  lowest_f 10.0693\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 11.9028 trial_f 11.9028 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 21: f 11.9277 trial_f 11.9277 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 22: f 12.0352 trial_f 12.0352 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 23: f 11.5829 trial_f 11.5829 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 24: f 11.5829 trial_f 11.8095 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 25: f 11.3382 trial_f 11.3382 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 26: f 11.3382 trial_f 11.7172 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 27: f 11.2691 trial_f 11.2691 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 28: f 11.7258 trial_f 11.7258 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 29: f 10.6623 trial_f 10.6623 accepted 1  lowest_f 10.0693\n",
      "adaptive stepsize: acceptance rate 0.800000 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "basinhopping step 30: f 10.7438 trial_f 10.7438 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 31: f 10.2029 trial_f 10.2029 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 32: f 10.2029 trial_f 11.0313 accepted 0  lowest_f 10.0693\n",
      "basinhopping step 33: f 10.126 trial_f 10.126 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 34: f 10.1781 trial_f 10.1781 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 35: f 10.1233 trial_f 10.1233 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 36: f 10.1542 trial_f 10.1542 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 37: f 10.483 trial_f 10.483 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 38: f 10.1085 trial_f 10.1085 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 39: f 10.1547 trial_f 10.1547 accepted 1  lowest_f 10.0693\n",
      "adaptive stepsize: acceptance rate 0.825000 target 0.500000 new stepsize 0.0762079 old stepsize 0.0685871\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 40: f 10.5991 trial_f 10.5991 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 41: f 10.3757 trial_f 10.3757 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 42: f 10.1289 trial_f 10.1289 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 43: f 11.0534 trial_f 11.0534 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 44: f 11.9025 trial_f 11.9025 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 45: f 11.5462 trial_f 11.5462 accepted 1  lowest_f 10.0693\n",
      "basinhopping step 46: f 11.7999 trial_f 11.7999 accepted 1  lowest_f 10.0693\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000020\n",
      "         Iterations: 34\n",
      "         Function evaluations: 83\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 0: f 0.00212313\n",
      "basinhopping step 1: f 0.430603 trial_f 0.430603 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 2: f 0.0773751 trial_f 0.0773751 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 3: f 0.0291919 trial_f 0.0291919 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 4: f 0.0255831 trial_f 0.0255831 accepted 1  lowest_f 0.00212313\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 0.153415 trial_f 0.153415 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 6: f 0.343819 trial_f 0.343819 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 7: f 0.0889686 trial_f 0.0889686 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 8: f 0.385208 trial_f 0.385208 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 9: f 0.308053 trial_f 0.308053 accepted 1  lowest_f 0.00212313\n",
      "adaptive stepsize: acceptance rate 0.900000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 0.308053 trial_f 0.864065 accepted 0  lowest_f 0.00212313\n",
      "basinhopping step 11: f 0.0171774 trial_f 0.0171774 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 12: f 0.0171774 trial_f 0.713849 accepted 0  lowest_f 0.00212313\n",
      "basinhopping step 13: f 0.0200269 trial_f 0.0200269 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 14: f 0.242015 trial_f 0.242015 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 15: f 0.489628 trial_f 0.489628 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 16: f 0.513843 trial_f 0.513843 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 17: f 0.132953 trial_f 0.132953 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 18: f 0.297588 trial_f 0.297588 accepted 1  lowest_f 0.00212313\n",
      "basinhopping step 19: f 0.442804 trial_f 0.442804 accepted 1  lowest_f 0.00212313\n",
      "adaptive stepsize: acceptance rate 0.850000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 0.442804 trial_f 0.731187 accepted 0  lowest_f 0.00212313\n",
      "basinhopping step 21: f 0.463394 trial_f 0.463394 accepted 1  lowest_f 0.00212313\n",
      "basinhopping finished\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000002\n",
      "         Iterations: 62\n",
      "         Function evaluations: 162\n",
      "basinhopping step 0: f 2.87522\n",
      "basinhopping step 1: f 2.51391 trial_f 2.51391 accepted 1  lowest_f 2.51391\n",
      "found new global minimum on step 1 with function value 2.51391\n",
      "basinhopping step 2: f 2.51391 trial_f 2.96125 accepted 0  lowest_f 2.51391\n",
      "basinhopping step 3: f 2.0076 trial_f 2.0076 accepted 1  lowest_f 2.0076\n",
      "found new global minimum on step 3 with function value 2.0076\n",
      "basinhopping step 4: f 2.55238 trial_f 2.55238 accepted 1  lowest_f 2.0076\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 5: f 2.65311 trial_f 2.65311 accepted 1  lowest_f 2.0076\n",
      "basinhopping step 6: f 2.65311 trial_f 2.8387 accepted 0  lowest_f 2.0076\n",
      "basinhopping step 7: f 2.74224 trial_f 2.74224 accepted 1  lowest_f 2.0076\n",
      "basinhopping step 8: f 2.13075 trial_f 2.13075 accepted 1  lowest_f 2.0076\n",
      "basinhopping step 9: f 1.98892 trial_f 1.98892 accepted 1  lowest_f 1.98892\n",
      "found new global minimum on step 9 with function value 1.98892\n",
      "adaptive stepsize: acceptance rate 0.700000 target 0.500000 new stepsize 0.0555556 old stepsize 0.05\n",
      "basinhopping step 10: f 1.98922 trial_f 1.98922 accepted 1  lowest_f 1.98892\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 11: f 1.98922 trial_f 2.36655 accepted 0  lowest_f 1.98892\n",
      "basinhopping step 12: f 1.80478 trial_f 1.80478 accepted 1  lowest_f 1.80478\n",
      "found new global minimum on step 12 with function value 1.80478\n",
      "basinhopping step 13: f 1.80478 trial_f 2.10749 accepted 0  lowest_f 1.80478\n",
      "basinhopping step 14: f 1.79139 trial_f 1.79139 accepted 1  lowest_f 1.79139\n",
      "found new global minimum on step 14 with function value 1.79139\n",
      "basinhopping step 15: f 1.75761 trial_f 1.75761 accepted 1  lowest_f 1.75761\n",
      "found new global minimum on step 15 with function value 1.75761\n",
      "basinhopping step 16: f 1.87706 trial_f 1.87706 accepted 1  lowest_f 1.75761\n",
      "basinhopping step 17: f 1.75003 trial_f 1.75003 accepted 1  lowest_f 1.75003\n",
      "found new global minimum on step 17 with function value 1.75003\n",
      "basinhopping step 18: f 1.84085 trial_f 1.84085 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 19: f 1.87338 trial_f 1.87338 accepted 1  lowest_f 1.75003\n",
      "adaptive stepsize: acceptance rate 0.750000 target 0.500000 new stepsize 0.0617284 old stepsize 0.0555556\n",
      "basinhopping step 20: f 2.20383 trial_f 2.20383 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 21: f 2.32985 trial_f 2.32985 accepted 1  lowest_f 1.75003\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 22: f 1.93977 trial_f 1.93977 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 23: f 1.94373 trial_f 1.94373 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 24: f 2.33347 trial_f 2.33347 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 25: f 2.90258 trial_f 2.90258 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 26: f 3.36247 trial_f 3.36247 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 27: f 3.29572 trial_f 3.29572 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 28: f 3.16539 trial_f 3.16539 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 29: f 3.39222 trial_f 3.39222 accepted 1  lowest_f 1.75003\n",
      "adaptive stepsize: acceptance rate 0.833333 target 0.500000 new stepsize 0.0685871 old stepsize 0.0617284\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 30: f 4.368 trial_f 4.368 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 31: f 4.37164 trial_f 4.37164 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 32: f 4.78257 trial_f 4.78257 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 33: f 4.37356 trial_f 4.37356 accepted 1  lowest_f 1.75003\n",
      "basinhopping step 34: f 4.80423 trial_f 4.80423 accepted 1  lowest_f 1.75003\n",
      "warning: basinhopping: local minimization failure\n",
      "basinhopping step 35: f 4.04858 trial_f 4.04858 accepted 1  lowest_f 1.75003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f2137b75e104>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'full'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m       \u001b[1;31m#finfo_list.append(m.fitinfo.T)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[1;31m#x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/build.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, save, savepth, ntrials, tol, maxfev, niter, disp, prob, multiopt, stage, inits, y)\u001b[0m\n\u001b[0;32m     74\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                   \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m(self, save, savepth)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'average'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__opt_routine__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_on\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'subjects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bootstrap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__indx_optimize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msavepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msavepth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36m__opt_routine__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mflat_yh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_fi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# STAGE 2 (Nudge/BasinHopping) & STAGE 3 (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_conditional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpopt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36moptimize_conditional\u001b[1;34m(self, p, y, precond)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprecond\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiopt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                   \u001b[1;31m# pretune conditional parameters (1/time)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                   \u001b[0mp2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_basin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;31m# STAGE 3: (Final Simplex)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/fit.pyc\u001b[0m in \u001b[0;36msingle_basin\u001b[1;34m(self, p, disp, interval, niter, stepsize, nsuccess)\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                   \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__update__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_flat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbwts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m                   \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasinhopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasinhopping_minimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstepsize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminimizer_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mniter_success\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnsuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m                   \u001b[0mxbasin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mbasinhopping\u001b[1;34m(func, x0, niter, T, stepsize, minimizer_kwargs, take_step, accept_test, callback, interval, disp, niter_success)\u001b[0m\n\u001b[0;32m    612\u001b[0m                \" successfully\"]\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mniter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mone_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36mone_cycle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[0mnew_global_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[0mxtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menergy_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monte_carlo_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m_monte_carlo_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;31m# do a local minimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mminres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_after_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mx_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0menergy_after_quench\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_basinhopping.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x0)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/_minimize.pyc\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[1;32m--> 447\u001b[1;33m                              **options)\n\u001b[0m\u001b[0;32m    448\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cobyla'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_minimize_cobyla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36m_minimize_tnc\u001b[1;34m(fun, x0, args, jac, bounds, eps, scale, offset, mesg_num, maxCGit, maxiter, eta, stepmx, accuracy, minfev, ftol, xtol, gtol, rescale, disp, callback, **unknown_options)\u001b[0m\n\u001b[0;32m    407\u001b[0m                                         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxCGit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxfun\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                         \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstepmx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mftol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                                         xtol, pgtol, rescale, callback)\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[0mfunv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjacv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/anaconda/lib/python2.7/site-packages/scipy/optimize/tnc.pyc\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapprox_fprime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36mbasinhopping_minimizer\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m                   \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.e5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msim_fx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwts\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__iter__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kyle/Dropbox/Git/radd/models.pyc\u001b[0m in \u001b[0;36msimulate_radd\u001b[1;34m(self, p, analyze)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mnssd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnssd\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mnss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnss\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mnc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mncond\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mdx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mntot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m             \u001b[0mDVg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxtb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mPg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'radd'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                   \u001b[0mDVg\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m=build.Model(data=redata, kind='xradd', depends_on={'a':'Cond'}, inits=inits)\n",
    "m.inits=popt\n",
    "for i in range(20):\n",
    "      m.optimize(stage='full', multiopt=True)      \n",
    "      #finfo_list.append(m.fitinfo.T) \n",
    "      #x = pd.DataFrame(m.fitinfo.T)#.to_csv('finfo.csv')\n",
    "      for c in cols:\n",
    "            fidf.loc[i, c]=m.fitinfo[c]\n",
    "      fidf.to_csv(\"finfo_xradd_a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = {'a_bsl':   0.529353,\n",
    "'a_pnl': 0.553150,\n",
    "'xb': 0.817502,\n",
    "'ssv': -1.104875,\n",
    "'tr': 0.185667,\n",
    "'v': 1.208608,\n",
    "'z': 0.0436727}\n",
    "\n",
    "x2 = {'a': 0.3964024,\n",
    " 'ssv': -0.7881214,\n",
    " 'tr': 0.2915253,\n",
    " 'v_bsl': 0.93931011,\n",
    " 'v_pnl': 0.88324705,\n",
    " 'xb': 1.667787,\n",
    " 'z': 0.1177627}\n",
    "\n",
    "x3={'a': 0.44534253,\n",
    " 'ssv':  -.9073797,\n",
    " 'tr_bsl':   0.29969275,\n",
    " 'tr_pnl':   0.31056620,\n",
    " 'v': 0.965766,\n",
    " 'xb': 1.52569355,\n",
    " 'z': 0.1591336}\n",
    "\n",
    "x4={'a': 0.44534253,\n",
    " 'ssv':  -1.564015,\n",
    " 'tr_bsl': 0.19521031,\n",
    " 'tr_pnl': 0.19703793,\n",
    " 'v_bsl': 1.80694264,\n",
    " 'v_pnl': 1.75763984,\n",
    " 'xb': 1.206618,\n",
    " 'z': 0.001013259}\n",
    "\n",
    "x4['tr'] = np.mean([x4['tr_bsl'], x4['tr_pnl']])\n",
    "x4['v'] = np.mean([x4['v_bsl'], x4['v_pnl']])\n",
    "x2['v'] = np.mean([x2['v_bsl'], x2['v_pnl']])\n",
    "x3['tr'] = np.mean([x3['tr_bsl'], x3['tr_pnl']])\n",
    "x1['a'] = np.mean([x1['a_bsl'], x1['a_pnl']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finfo_list, yhat_list = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 26\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000052\n",
      "         Iterations: 87\n",
      "         Function evaluations: 240\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 36\n",
      "         Function evaluations: 84\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 22\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 21\n",
      "         Function evaluations: 56\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000057\n",
      "         Iterations: 23\n",
      "         Function evaluations: 65\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000051\n",
      "         Iterations: 141\n",
      "         Function evaluations: 370\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 59\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 71\n",
      "         Function evaluations: 173\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 24\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 28\n",
      "         Function evaluations: 71\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000013\n",
      "         Iterations: 21\n",
      "         Function evaluations: 58\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000073\n",
      "         Iterations: 99\n",
      "         Function evaluations: 268\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000167\n",
      "         Iterations: 70\n",
      "         Function evaluations: 183\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 23\n",
      "         Function evaluations: 57\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000048\n",
      "         Iterations: 79\n",
      "         Function evaluations: 212\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 25\n",
      "         Function evaluations: 60\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000166\n",
      "         Iterations: 55\n",
      "         Function evaluations: 134\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 25\n",
      "         Function evaluations: 64\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 26\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000170\n",
      "         Iterations: 39\n",
      "         Function evaluations: 105\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 20\n",
      "         Function evaluations: 56\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000063\n",
      "         Iterations: 29\n",
      "         Function evaluations: 72\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 21\n",
      "         Function evaluations: 54\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000060\n",
      "         Iterations: 28\n",
      "         Function evaluations: 74\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000016\n",
      "         Iterations: 27\n",
      "         Function evaluations: 63\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000059\n",
      "         Iterations: 24\n",
      "         Function evaluations: 67\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000173\n",
      "         Iterations: 82\n",
      "         Function evaluations: 216\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 29\n",
      "         Function evaluations: 68\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000017\n",
      "         Iterations: 23\n",
      "         Function evaluations: 62\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000058\n",
      "         Iterations: 42\n",
      "         Function evaluations: 114\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000050\n",
      "         Iterations: 79\n",
      "         Function evaluations: 213\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000015\n",
      "         Iterations: 28\n",
      "         Function evaluations: 60\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000061\n",
      "         Iterations: 31\n",
      "         Function evaluations: 82\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000014\n",
      "         Iterations: 23\n",
      "         Function evaluations: 53\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000172\n",
      "         Iterations: 41\n",
      "         Function evaluations: 95\n",
      "Warning: Maximum number of function evaluations has been exceeded.\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "      \n",
    "      xinits_list = [deepcopy(xdct) for xdct in [x1,x2,x3,x4]]\n",
    "      parameter = 'v'\n",
    "      depends_on = {parameter:'Cond'}\n",
    "\n",
    "      d = '/'.join(['FinalRe', parameter+'iii'])\n",
    "      if not os.path.isdir(pth+d):\n",
    "            os.mkdir(pth+d)\n",
    "      os.chdir(pth+d)\n",
    "\n",
    "      for xi in xinits_list:\n",
    "            model = build.Model(data=redata, kind='xradd', inits=xi, depends_on=depends_on)\n",
    "            model.make_optimizer(tol=1.e-5, multiopt=True, maxfev=500)\n",
    "            opt=model.opt\n",
    "            opt.make_simulator()\n",
    "\n",
    "            ydata, ywts = model.avg_y, model.avg_wts\n",
    "            # STAGE 3 (Final Simplex)\n",
    "            yhat, finfo, xiv = opt.gradient_descent(y=ydata, wts=ywts, inits=xi, is_flat=False)\n",
    "\n",
    "            finfo_list.append(finfo)\n",
    "            yhat_list.append(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfx = pd.DataFrame([fi.T for fi in finfo_list])\n",
    "dff = dfx[['cnvrg', 'logp', 'chi', 'rchi', 'AIC', 'BIC', 'a', 'v_bsl', 'v_pnl', 'ssv', 'xb', 'tr', 'z']]\n",
    "dff.to_csv('xradd_v_bootinfo.csv', index=False)\n",
    "\n",
    "yfits = np.vstack([np.vstack(yh.reshape(2,16)) for yh in yhat_list])\n",
    "cond = ['bsl', 'pnl']*int(len(yfits)/2)\n",
    "yhatdf = pd.DataFrame(yfits)\n",
    "yhatdf.insert(0, 'Cond', cond)\n",
    "yhatdf.to_csv('xradd_v_bootfits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,3,figsize=(12, 7))\n",
    "sns.set_context('notebook', font_scale=1.6)\n",
    "fits=m.fits.reshape(2,16)\n",
    "y=m.avg_y\n",
    "labels=['Baseline', 'Caution']\n",
    "datas=[redata.query('Cond==\"bsl\"'), redata.query('Cond==\"pnl\"')]\n",
    "colors=[\"#e74c3c\"]*2\n",
    "for i in range(m.ncond):\n",
    "      vis.plot_fits(y[i], fits[i], kind='radd', colors=[\"#e74c3c\"]*2, data=datas[i], axes=axes[i])\n",
    "\n",
    "for ax in axes.flatten():\n",
    "      if ax.is_last_col():\n",
    "            continue\n",
    "      ax.set_ylim(0,11)\n",
    "\n",
    "plt.savefig('re_drift_fitsII.png', dpi=500)\n",
    "plt.savefig('re_drift_fitsII.svg', rasterized=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
